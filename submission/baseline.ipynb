{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a35d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import json\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f974c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load label for train \n",
    "train_label_file = open('project-data/train.label.txt', 'r')\n",
    "train_labels = train_label_file.readlines()\n",
    "train_labels = [label.strip('\\n') for label in train_labels]\n",
    "\n",
    "#load label for dev \n",
    "dev_label_file = open('project-data/dev.label.txt', 'r')\n",
    "dev_labels = dev_label_file.readlines()\n",
    "dev_labels = [label.strip('\\n') for label in dev_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb4021e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open train text file\n",
    "f = open(f'./tweet_text.pckl','rb')\n",
    "train_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "# open dev text file\n",
    "f = open(f'./dev_tweet_text.pckl','rb')\n",
    "dev_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# open test text file\n",
    "f = open(f'./test_tweet_text.pckl','rb')\n",
    "test_data = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45f8d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cleaning the tweets\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text) #remove @mention\n",
    "    text = re.sub(r'#','',text) # remove the hashtag symbol\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '',text) #remove hyperlink\n",
    "    text = re.sub(r'\\n','',text) # remove \\n \n",
    "    text = re.sub(r'\\r','',text) # remove \\r\n",
    "    text = re.sub(r'[0-9]+','',text) #remove all the number\n",
    "    text = re.sub(r'\\W+', ' ', text) #remove special characters\n",
    "    text = text.strip().lower()\n",
    "    if len(text) != 0:\n",
    "        return text\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "for i in range(len(train_data)):\n",
    "    for j in range(len(train_data[i])):\n",
    "        train_data[i][j] = clean_text(train_data[i][j])\n",
    "    train_data[i] = [x for x in train_data[i] if x is not None]\n",
    "        \n",
    "for i in range(len(dev_data)):\n",
    "    for j in range(len(dev_data[i])):\n",
    "        dev_data[i][j] = clean_text(dev_data[i][j])\n",
    "    dev_data[i] = [x for x in dev_data[i] if x is not None]\n",
    "    \n",
    "for i in range(len(test_data)):\n",
    "    for j in range(len(test_data[i])):\n",
    "        test_data[i][j] = clean_text(test_data[i][j])\n",
    "    test_data[i] = [x for x in test_data[i] if x is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e188276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge source tweeet and reply tweet together for train data\n",
    "train_merge_events=[]\n",
    "for event in train_data:\n",
    "    merge = ''\n",
    "    for tweet in event:\n",
    "        merge = merge + tweet\n",
    "    train_merge_events.append(merge)\n",
    "    \n",
    "    \n",
    "# merge source tweeet and reply tweet together for dev data\n",
    "dev_merge_events=[]\n",
    "for event in dev_data:\n",
    "    merge = ''\n",
    "    for tweet in event:\n",
    "        merge = merge + tweet\n",
    "    dev_merge_events.append(merge)\n",
    "\n",
    "# merge source tweeet and reply tweet together for test data    \n",
    "test_merge_events=[]\n",
    "for event in test_data:\n",
    "    merge = ''\n",
    "    for tweet in event:\n",
    "        merge = merge + tweet\n",
    "    test_merge_events.append(merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29a7d7",
   "metadata": {},
   "source": [
    "## CounVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165fcf24",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68e7b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to write manually for better tokenize\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "x_train = cv.fit_transform(train_merge_events)\n",
    "y_train = train_labels\n",
    "\n",
    "x_dev = cv.transform(dev_merge_events)\n",
    "y_dev = dev_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b53067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),\n",
    "        MultinomialNB(),LinearSVC(),LogisticRegression()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e45b38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "accuracy\n",
      "0.8142480211081794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.81      0.99      0.89      1475\n",
      "      rumour       0.82      0.21      0.33       420\n",
      "\n",
      "    accuracy                           0.81      1895\n",
      "   macro avg       0.82      0.60      0.61      1895\n",
      "weighted avg       0.82      0.81      0.77      1895\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "accuracy\n",
      "0.8221635883905013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.87      0.91      0.89      1475\n",
      "      rumour       0.62      0.51      0.56       420\n",
      "\n",
      "    accuracy                           0.82      1895\n",
      "   macro avg       0.74      0.71      0.72      1895\n",
      "weighted avg       0.81      0.82      0.82      1895\n",
      "\n",
      "RandomForestClassifier()\n",
      "accuracy\n",
      "0.8369393139841689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.83      0.99      0.90      1475\n",
      "      rumour       0.88      0.31      0.46       420\n",
      "\n",
      "    accuracy                           0.84      1895\n",
      "   macro avg       0.86      0.65      0.68      1895\n",
      "weighted avg       0.84      0.84      0.80      1895\n",
      "\n",
      "MultinomialNB()\n",
      "accuracy\n",
      "0.8675461741424803\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.93      0.89      0.91      1475\n",
      "      rumour       0.67      0.78      0.72       420\n",
      "\n",
      "    accuracy                           0.87      1895\n",
      "   macro avg       0.80      0.84      0.82      1895\n",
      "weighted avg       0.88      0.87      0.87      1895\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC()\n",
      "accuracy\n",
      "0.8707124010554089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.89      0.95      0.92      1475\n",
      "      rumour       0.76      0.61      0.68       420\n",
      "\n",
      "    accuracy                           0.87      1895\n",
      "   macro avg       0.83      0.78      0.80      1895\n",
      "weighted avg       0.86      0.87      0.87      1895\n",
      "\n",
      "LogisticRegression()\n",
      "accuracy\n",
      "0.891292875989446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.90      0.97      0.93      1475\n",
      "      rumour       0.85      0.61      0.71       420\n",
      "\n",
      "    accuracy                           0.89      1895\n",
      "   macro avg       0.88      0.79      0.82      1895\n",
      "weighted avg       0.89      0.89      0.88      1895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def do_multiple_10foldcrossvalidation(clfs,data,classifications):\n",
    "    for clf in clfs:\n",
    "        predictions = model_selection.cross_val_predict(clf, data,classifications, cv=10)\n",
    "        print (clf)\n",
    "        print (\"accuracy\")\n",
    "        print (accuracy_score(classifications,predictions))\n",
    "        print (classification_report(classifications,predictions))\n",
    "        \n",
    "do_multiple_10foldcrossvalidation(clfs,x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d50fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k fold to find the optimize hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4059f93e",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db3276c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the rumour class:\n",
      "Precision = 0.8584905660377359\n",
      "Recall    = 0.6546762589928058\n",
      "F1        = 0.7428571428571429\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr_predict = lr.fit(x_train, y_train).predict(x_dev)    \n",
    "\n",
    "df = pd.DataFrame({\"Predicted\": lr_predict}) \n",
    "df.to_csv('dev.cv.lr.txt', header=None, index=None)\n",
    "!python eval.py --predictions dev.cv.lr.txt --groundtruth dev.label.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8389428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the rumour class:\n",
      "Precision = 0.7588652482269503\n",
      "Recall    = 0.7697841726618705\n",
      "F1        = 0.7642857142857142\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB()\n",
    "nb = MultinomialNB(alpha= 0.005)\n",
    "nb_predict = nb.fit(x_train, y_train).predict(x_dev)    \n",
    "\n",
    "df = pd.DataFrame({\"Predicted\": nb_predict}) \n",
    "df.to_csv('dev.cv.nb.txt', header=None, index=None)\n",
    "!python eval.py --predictions dev.cv.nb.txt --groundtruth dev.label.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8f7db11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the rumour class:\n",
      "Precision = 0.7931034482758621\n",
      "Recall    = 0.6618705035971223\n",
      "F1        = 0.7215686274509805\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC\n",
    "SVC = LinearSVC(max_iter=10000)\n",
    "SVC_predict = SVC.fit(x_train, y_train).predict(x_dev)    \n",
    "\n",
    "df = pd.DataFrame({\"Predicted\": SVC_predict}) \n",
    "df.to_csv('dev.cv.svc.txt', header=None, index=None)\n",
    "!python eval.py --predictions dev.cv.svc.txt --groundtruth dev.label.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16d541e",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cdf94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = cv.transform(test_merge_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34090924",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB(alpha= 0.005)\n",
    "nb_predict = nb.fit(x_train, y_train).predict(x_test)    \n",
    "\n",
    "predict=[]\n",
    "for result in nb_predict:\n",
    "    if result == \"nonrumour\":\n",
    "        predict.append(0)\n",
    "    else:\n",
    "        predict.append(1)\n",
    "df = pd.DataFrame({\"Id\": range(len(predict)),\"Predicted\": predict}) \n",
    "df.to_csv('cv_nb.csv',index=False)\n",
    "\n",
    "# Precision =  0.8 on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18a15430",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC = LinearSVC(max_iter=10000)\n",
    "SVC_predict = SVC.fit(x_train, y_train).predict(x_test)    \n",
    "\n",
    "\n",
    "predict=[]\n",
    "for result in SVC_predict:\n",
    "    if result == \"nonrumour\":\n",
    "        predict.append(0)\n",
    "    else:\n",
    "        predict.append(1)\n",
    "df = pd.DataFrame({\"Id\": range(len(predict)),\"Predicted\": predict}) \n",
    "df.to_csv('cv_scv.csv',index=False)\n",
    "\n",
    "# o.75 on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f30382e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr_predict = lr.fit(x_train, y_train).predict(x_test)    \n",
    "\n",
    "predict=[]\n",
    "for result in lr_predict:\n",
    "    if result == \"nonrumour\":\n",
    "        predict.append(0)\n",
    "    else:\n",
    "        predict.append(1)\n",
    "df = pd.DataFrame({\"Id\": range(len(predict)),\"Predicted\": predict}) \n",
    "df.to_csv('cv_lr.csv',index=False)\n",
    "\n",
    "# Precision =  0.76744 on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a6ca1",
   "metadata": {},
   "source": [
    "## Using td-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d69ffda",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "121c3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to write manually for better tokenize\n",
    "td = TfidfVectorizer(stop_words='english')\n",
    "x_train = td.fit_transform(train_merge_events)\n",
    "y_train = train_labels\n",
    "\n",
    "x_dev = td.transform(dev_merge_events)\n",
    "y_dev = dev_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be054c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "accuracy\n",
      "0.7868073878627968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.79      1.00      0.88      1475\n",
      "      rumour       0.79      0.05      0.10       420\n",
      "\n",
      "    accuracy                           0.79      1895\n",
      "   macro avg       0.79      0.52      0.49      1895\n",
      "weighted avg       0.79      0.79      0.71      1895\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "accuracy\n",
      "0.8269129287598944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.87      0.91      0.89      1475\n",
      "      rumour       0.63      0.54      0.58       420\n",
      "\n",
      "    accuracy                           0.83      1895\n",
      "   macro avg       0.75      0.73      0.74      1895\n",
      "weighted avg       0.82      0.83      0.82      1895\n",
      "\n",
      "RandomForestClassifier()\n",
      "accuracy\n",
      "0.8253298153034301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.82      1.00      0.90      1475\n",
      "      rumour       0.94      0.23      0.36       420\n",
      "\n",
      "    accuracy                           0.83      1895\n",
      "   macro avg       0.88      0.61      0.63      1895\n",
      "weighted avg       0.85      0.83      0.78      1895\n",
      "\n",
      "MultinomialNB()\n",
      "accuracy\n",
      "0.7920844327176781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.79      1.00      0.88      1475\n",
      "      rumour       1.00      0.06      0.12       420\n",
      "\n",
      "    accuracy                           0.79      1895\n",
      "   macro avg       0.89      0.53      0.50      1895\n",
      "weighted avg       0.84      0.79      0.71      1895\n",
      "\n",
      "LinearSVC()\n",
      "accuracy\n",
      "0.8944591029023746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.89      0.99      0.94      1475\n",
      "      rumour       0.92      0.57      0.71       420\n",
      "\n",
      "    accuracy                           0.89      1895\n",
      "   macro avg       0.91      0.78      0.82      1895\n",
      "weighted avg       0.90      0.89      0.88      1895\n",
      "\n",
      "LogisticRegression()\n",
      "accuracy\n",
      "0.8200527704485489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.81      1.00      0.90      1475\n",
      "      rumour       0.95      0.20      0.33       420\n",
      "\n",
      "    accuracy                           0.82      1895\n",
      "   macro avg       0.88      0.60      0.61      1895\n",
      "weighted avg       0.84      0.82      0.77      1895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def do_multiple_10foldcrossvalidation(clfs,data,classifications):\n",
    "    for clf in clfs:\n",
    "        predictions = model_selection.cross_val_predict(clf, data,classifications, cv=10)\n",
    "        print (clf)\n",
    "        print (\"accuracy\")\n",
    "        print (accuracy_score(classifications,predictions))\n",
    "        print (classification_report(classifications,predictions))\n",
    "        \n",
    "do_multiple_10foldcrossvalidation(clfs,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18e43d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k fold to find the optimize hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b3cbb8",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5d716421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the rumour class:\n",
      "Precision = 0.975609756097561\n",
      "Recall    = 0.28776978417266186\n",
      "F1        = 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr_predict = lr.fit(x_train, y_train).predict(x_dev)    \n",
    "\n",
    "df = pd.DataFrame({\"Predicted\": lr_predict}) \n",
    "df.to_csv('dev.tf.lr.txt', header=None, index=None)\n",
    "!python eval.py --predictions dev.tf.lr.txt --groundtruth dev.label.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6c9d01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the rumour class:\n",
      "Precision = 0.8148148148148148\n",
      "Recall    = 0.7913669064748201\n",
      "F1        = 0.8029197080291969\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB()\n",
    "nb = MultinomialNB(alpha= 0.005)\n",
    "nb_predict = nb.fit(x_train, y_train).predict(x_dev)    \n",
    "\n",
    "df = pd.DataFrame({\"Predicted\": nb_predict}) \n",
    "df.to_csv('dev.tf.nb.txt', header=None, index=None)\n",
    "!python eval.py --predictions dev.tf.nb.txt --groundtruth dev.label.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c72cae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the rumour class:\n",
      "Precision = 0.8990825688073395\n",
      "Recall    = 0.7050359712230215\n",
      "F1        = 0.7903225806451614\n"
     ]
    }
   ],
   "source": [
    "# LinearSVC\n",
    "SVC = LinearSVC(max_iter=10000)\n",
    "SVC_predict = SVC.fit(x_train, y_train).predict(x_dev)    \n",
    "\n",
    "df = pd.DataFrame({\"Predicted\": SVC_predict}) \n",
    "df.to_csv('dev.tf.svc.txt', header=None, index=None)\n",
    "!python eval.py --predictions dev.tf.svc.txt --groundtruth dev.label.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fcb225",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e1786b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = td.transform(test_merge_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d692ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB(alpha= 0.005)\n",
    "nb_predict = nb.fit(x_train, y_train).predict(x_test)    \n",
    "\n",
    "predict=[]\n",
    "for result in nb_predict:\n",
    "    if result == \"nonrumour\":\n",
    "        predict.append(0)\n",
    "    else:\n",
    "        predict.append(1)\n",
    "df = pd.DataFrame({\"Id\": range(len(predict)),\"Predicted\": predict}) \n",
    "df.to_csv('tf_nb.csv',index=False)\n",
    "\n",
    "# Precision =  0.82 on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "479c9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC = LinearSVC(max_iter=10000)\n",
    "SVC_predict = SVC.fit(x_train, y_train).predict(x_test)    \n",
    "\n",
    "\n",
    "predict=[]\n",
    "for result in SVC_predict:\n",
    "    if result == \"nonrumour\":\n",
    "        predict.append(0)\n",
    "    else:\n",
    "        predict.append(1)\n",
    "df = pd.DataFrame({\"Id\": range(len(predict)),\"Predicted\": predict}) \n",
    "df.to_csv('tf_scv.csv',index=False)\n",
    "\n",
    "# Precision =  0.85714 on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "940910d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr_predict = lr.fit(x_train, y_train).predict(x_test)    \n",
    "\n",
    "predict=[]\n",
    "for result in lr_predict:\n",
    "    if result == \"nonrumour\":\n",
    "        predict.append(0)\n",
    "    else:\n",
    "        predict.append(1)\n",
    "df = pd.DataFrame({\"Id\": range(len(predict)),\"Predicted\": predict}) \n",
    "df.to_csv('tf_lr.csv',index=False)\n",
    "\n",
    "# Precision =  0.57142 on Kaggle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
