{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a35d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f974c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data \n",
    "train_data_file = open('project-data/train.data.txt', 'r')\n",
    "train_lines = train_data_file.readlines()\n",
    "train_events =[]\n",
    "# Strips the newline character\n",
    "for line in train_lines:\n",
    "    train_events.append(list(map(int,line.strip('\\n').split(','))))\n",
    "    \n",
    "train_label_file = open('project-data/train.label.txt', 'r')\n",
    "train_labels = train_label_file.readlines()\n",
    "train_labels = [label.strip('\\n') for label in train_labels]\n",
    "\n",
    "\n",
    "dev_data_file = open('project-data/dev.data.txt', 'r')\n",
    "dev_lines = dev_data_file.readlines()\n",
    "dev_events =[]\n",
    "# Strips the newline character\n",
    "for line in dev_lines:\n",
    "    dev_events.append(list(map(int,line.strip('\\n').split(','))))\n",
    "    \n",
    "dev_label_file = open('project-data/dev.label.txt', 'r')\n",
    "dev_labels = dev_label_file.readlines()\n",
    "dev_labels = [label.strip('\\n') for label in dev_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e4e3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config to access tweeter API\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "consumer_key = config['twitter']['consumer_key']\n",
    "consumer_secret = config['twitter']['consumer_secret']\n",
    "\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "305b8c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authentication\n",
    "client = tweepy.Client(consumer_key=consumer_key, consumer_secret=consumer_secret,\n",
    "                                   access_token=access_token, access_token_secret=access_token_secret,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdd867de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_tweets only return 100 results, handle the case when there is more than 100\n",
    "def lookup_tweets(tweet_IDs, client):\n",
    "    full_tweets = []\n",
    "    tweet_count = len(tweet_IDs)\n",
    "    for i in range(int((tweet_count / 100) + 1)):\n",
    "        # Catch the last group if it is less than 100 tweets\n",
    "        end_loc = min((i + 1) * 100, tweet_count)\n",
    "        if tweet_IDs[i * 100:end_loc]:\n",
    "            tweets = client.get_tweets(tweet_IDs[i * 100:end_loc],user_auth=True).data\n",
    "            if tweets:\n",
    "                full_tweets.extend(tweets)\n",
    "    return full_tweets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc875eec",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17744/1230150304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_events_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_events\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlookup_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_event_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_events_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_event_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17744/631739775.py\u001b[0m in \u001b[0;36mlookup_tweets\u001b[1;34m(tweet_IDs, client)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mend_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtweet_IDs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_loc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_IDs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_loc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser_auth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mfull_tweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\tweepy\\client.py\u001b[0m in \u001b[0;36mget_tweets\u001b[1;34m(self, ids, user_auth, **params)\u001b[0m\n\u001b[0;32m   1701\u001b[0m                 \u001b[1;34m\"ids\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"expansions\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"media.fields\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"place.fields\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1702\u001b[0m                 \u001b[1;34m\"poll.fields\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tweet.fields\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"user.fields\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1703\u001b[1;33m             ), data_type=Tweet, user_auth=user_auth\n\u001b[0m\u001b[0;32m   1704\u001b[0m         )\n\u001b[0;32m   1705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\tweepy\\client.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         response = self.request(method, route, params=request_params,\n\u001b[1;32m--> 127\u001b[1;33m                                 json=json, user_auth=user_auth)\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_type\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\tweepy\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m     83\u001b[0m         with self.session.request(\n\u001b[0;32m     84\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mroute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         ) as response:\n\u001b[0;32m     87\u001b[0m             log.debug(\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    527\u001b[0m         }\n\u001b[0;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m                 )\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m             )\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1371\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1373\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1374\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1071\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# get the text of all events\n",
    "train_events_text=[]\n",
    "for event in train_events:\n",
    "    results = lookup_tweets(event, client)\n",
    "    train_event_text=[tweet.text for tweet in results]\n",
    "    train_events_text.append(train_event_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa941502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to pickle file\n",
    "f = open(f'./tweet_text.pckl','wb')\n",
    "pickle.dump(train_events_text,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a7276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the text of all events\n",
    "dev_events_text=[]\n",
    "for event in dev_events:\n",
    "    results = lookup_tweets(event, client)\n",
    "    dev_event_text=[tweet.text for tweet in results]\n",
    "    dev_events_text.append(dev_event_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "140e26d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to pickle file\n",
    "f = open(f'./dev_tweet_text.pckl','wb')\n",
    "pickle.dump(dev_events_text,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce426aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open train text file\n",
    "f = open(f'./tweet_text.pckl','rb')\n",
    "train_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "# open dev text file\n",
    "f = open(f'./dev_tweet_text.pckl','rb')\n",
    "dev_data = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45f8d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text) #remove @mention\n",
    "    text = re.sub(r'#','',text) # remove the hashtag symbol\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '',text) #remove hyperlink\n",
    "    text = re.sub(r'\\n','',text) # remove \\n \n",
    "    text = re.sub(r'\\W+', '', text) #remove special characters\n",
    "    return text\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    for j in range(len(train_data[i])):\n",
    "        train_data[i][j] = clean_text(train_data[i][j])\n",
    "        \n",
    "for i in range(len(dev_data)):\n",
    "    for j in range(len(dev_data[i])):\n",
    "        dev_data[i][j] = clean_text(dev_data[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e188276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge source tweeet and reply tweet together for train data\n",
    "train_merge_events=[]\n",
    "for event in train_data:\n",
    "    merge = ''\n",
    "    for tweet in event:\n",
    "        merge = merge + tweet\n",
    "    train_merge_events.append(merge)\n",
    "    \n",
    "    \n",
    "# merge source tweeet and reply tweet together for dev data\n",
    "dev_merge_events=[]\n",
    "for event in dev_data:\n",
    "    merge = ''\n",
    "    for tweet in event:\n",
    "        merge = merge + tweet\n",
    "    dev_merge_events.append(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86ecc06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweet(tweet):\n",
    "    \"\"\"Get all of the tokens in a set of tweets\"\"\"\n",
    "    twt = nltk.tokenize.TweetTokenizer()\n",
    "    # combine stop words and punctuation\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    stop = stopwords + list(string.punctuation)\n",
    "    # filter out stop words and punctuation and send to lower case\n",
    "    tokens = [token.lower() for token in twt.tokenize(tweet)\n",
    "              if token.lower() not in stop]\n",
    "    tokens = [word for word in tokens if re.search('[a-zA-Z]',word) is not None] # filter out word not contain alphabet\n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eedf7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweetv2(tweet):\n",
    "    \"\"\"Get all of the tokens in a set of tweets\"\"\"\n",
    "    twt = nltk.tokenize.TweetTokenizer()\n",
    "    # combine stop words and punctuation\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    stop = stopwords + list(string.punctuation)\n",
    "    # create the stemmer\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    # filter out stop words and punctuation and send to lower case\n",
    "    tokens = [ stemmer.stem(token) for token in twt.tokenize(tweet)\n",
    "              if token.lower() not in stop]\n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29a7d7",
   "metadata": {},
   "source": [
    "### Normal bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "422ff238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of word \n",
    "def bow(data,labels):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(data)):\n",
    "        tokens = tokenize_tweet(data[i])\n",
    "        \n",
    "        vocab = collections.defaultdict(int)\n",
    "        for word in tokens:\n",
    "            vocab[word] += 1 \n",
    "        x.append(vocab)\n",
    "        y.append(labels[i])\n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68e7b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = bow(train_merge_events,train_labels)\n",
    "x_dev,y_dev = bow(dev_merge_events,dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a1b9c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_dev = vectorizer.transform(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e8eb610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With alpha = 0.001 the accuracy of Naive Bayes is 0.90032\n",
      "With alpha = 0.005 the accuracy of Naive Bayes is 0.89715\n",
      "With alpha = 0.01 the accuracy of Naive Bayes is 0.88924\n",
      "With alpha = 0.1 the accuracy of Naive Bayes is 0.88608\n",
      "With alpha = 0.3 the accuracy of Naive Bayes is 0.87816\n",
      "With alpha = 0.5 the accuracy of Naive Bayes is 0.88133\n",
      "With alpha = 1 the accuracy of Naive Bayes is 0.88608\n",
      "The best setting for Naive Bayes is alpha = 0.001 with accuracy = 0.90032\n"
     ]
    }
   ],
   "source": [
    "# k fold to find the optimize hyperparameter\n",
    "alphas = [0.001,0.005,0.01,0.1,0.3,0.5,1]\n",
    "max_nb = 0\n",
    "for alpha in alphas:\n",
    "    nb = MultinomialNB(alpha=alpha)\n",
    "    nb_predict = nb.fit(x_train, y_train).predict(x_dev)    \n",
    "    nb_accuracy = accuracy_score(y_dev,nb_predict)\n",
    "    print('With alpha = {alpha} the accuracy of Naive Bayes is {acc:.5f}'.format(alpha=alpha, acc = nb_accuracy))\n",
    "    if nb_accuracy > max_nb:\n",
    "        max_nb = nb_accuracy\n",
    "        max_alpha = alpha\n",
    "print(\"The best setting for Naive Bayes is alpha = {alpha} with accuracy = {acc:.5f}\".format(alpha=max_alpha,acc=max_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f27fe4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using this solver  newton-cg\n",
      "With C = 100 and solver  = newton-cg the acciracy of Logistic Regression is 0.9113924050632911\n",
      "With C = 10 and solver  = newton-cg the acciracy of Logistic Regression is 0.9145569620253164\n",
      "With C = 1.0 and solver  = newton-cg the acciracy of Logistic Regression is 0.9129746835443038\n",
      "With C = 0.1 and solver  = newton-cg the acciracy of Logistic Regression is 0.8876582278481012\n",
      "With C = 0.01 and solver  = newton-cg the acciracy of Logistic Regression is 0.8433544303797469\n",
      "With C = 0.001 and solver  = newton-cg the acciracy of Logistic Regression is 0.7958860759493671\n",
      "Using this solver  lbfgs\n",
      "With C = 100 and solver  = lbfgs the acciracy of Logistic Regression is 0.9113924050632911\n",
      "With C = 10 and solver  = lbfgs the acciracy of Logistic Regression is 0.9145569620253164\n",
      "With C = 1.0 and solver  = lbfgs the acciracy of Logistic Regression is 0.9129746835443038\n",
      "With C = 0.1 and solver  = lbfgs the acciracy of Logistic Regression is 0.8876582278481012\n",
      "With C = 0.01 and solver  = lbfgs the acciracy of Logistic Regression is 0.8433544303797469\n",
      "With C = 0.001 and solver  = lbfgs the acciracy of Logistic Regression is 0.7958860759493671\n",
      "Using this solver  liblinear\n",
      "With C = 100 and solver  = liblinear the acciracy of Logistic Regression is 0.9113924050632911\n",
      "With C = 10 and solver  = liblinear the acciracy of Logistic Regression is 0.9129746835443038\n",
      "With C = 1.0 and solver  = liblinear the acciracy of Logistic Regression is 0.9129746835443038\n",
      "With C = 0.1 and solver  = liblinear the acciracy of Logistic Regression is 0.8987341772151899\n",
      "With C = 0.01 and solver  = liblinear the acciracy of Logistic Regression is 0.8544303797468354\n",
      "With C = 0.001 and solver  = liblinear the acciracy of Logistic Regression is 0.8306962025316456\n",
      "Using this solver  sag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 100 and solver  = sag the acciracy of Logistic Regression is 0.9272151898734177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 10 and solver  = sag the acciracy of Logistic Regression is 0.9272151898734177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 1.0 and solver  = sag the acciracy of Logistic Regression is 0.9272151898734177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 0.1 and solver  = sag the acciracy of Logistic Regression is 0.9224683544303798\n",
      "With C = 0.01 and solver  = sag the acciracy of Logistic Regression is 0.9145569620253164\n",
      "With C = 0.001 and solver  = sag the acciracy of Logistic Regression is 0.8781645569620253\n",
      "Using this solver  saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 100 and solver  = saga the acciracy of Logistic Regression is 0.9272151898734177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 10 and solver  = saga the acciracy of Logistic Regression is 0.9272151898734177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 1.0 and solver  = saga the acciracy of Logistic Regression is 0.9272151898734177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 0.1 and solver  = saga the acciracy of Logistic Regression is 0.9240506329113924\n",
      "With C = 0.01 and solver  = saga the acciracy of Logistic Regression is 0.9145569620253164\n",
      "With C = 0.001 and solver  = saga the acciracy of Logistic Regression is 0.8718354430379747\n",
      "The best setting for Logistic Regression is c = 100 and solver = sag with accuracy = 0.92722\n"
     ]
    }
   ],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear','sag','saga']\n",
    "c_values = [ 100,10,1.0, 0.1, 0.01,0.001]\n",
    "max_lr = 0\n",
    "for solver in solvers:\n",
    "    print('Using this solver ',solver )\n",
    "    for c_value in c_values:\n",
    "        lr = LogisticRegression(C=c_value, penalty='l2', solver=solver,max_iter=1000)\n",
    "        lr_predict = lr.fit(x_train, y_train).predict(x_dev)    \n",
    "        lr_accuracy = accuracy_score(y_dev,lr_predict)\n",
    "        print('With C = {c} and solver  = {sol} the acciracy of Logistic Regression is {acc}'.format(c=c_value,sol=solver,acc= lr_accuracy))\n",
    "        if lr_accuracy > max_lr:\n",
    "            max_lr = lr_accuracy\n",
    "            max_c_value = c_value\n",
    "            max_solver = solver\n",
    "print(\"The best setting for Logistic Regression is c = {c} and solver = {sol} with accuracy = {acc:.5f}\".format(c=max_c_value,sol=max_solver,acc=max_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b53067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clfs = [KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),\n",
    "        MultinomialNB(),LinearSVC(),LogisticRegression()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e45b38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "accuracy\n",
      "0.7915567282321899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.79      1.00      0.88      1475\n",
      "      rumour       0.86      0.07      0.13       420\n",
      "\n",
      "    accuracy                           0.79      1895\n",
      "   macro avg       0.82      0.53      0.51      1895\n",
      "weighted avg       0.81      0.79      0.72      1895\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "accuracy\n",
      "0.833245382585752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.88      0.91      0.89      1475\n",
      "      rumour       0.64      0.56      0.60       420\n",
      "\n",
      "    accuracy                           0.83      1895\n",
      "   macro avg       0.76      0.73      0.75      1895\n",
      "weighted avg       0.83      0.83      0.83      1895\n",
      "\n",
      "RandomForestClassifier()\n",
      "accuracy\n",
      "0.8401055408970977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.83      0.99      0.91      1475\n",
      "      rumour       0.93      0.30      0.45       420\n",
      "\n",
      "    accuracy                           0.84      1895\n",
      "   macro avg       0.88      0.65      0.68      1895\n",
      "weighted avg       0.86      0.84      0.81      1895\n",
      "\n",
      "MultinomialNB()\n",
      "accuracy\n",
      "0.7968337730870713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.79      1.00      0.88      1475\n",
      "      rumour       0.95      0.09      0.16       420\n",
      "\n",
      "    accuracy                           0.80      1895\n",
      "   macro avg       0.87      0.54      0.52      1895\n",
      "weighted avg       0.83      0.80      0.72      1895\n",
      "\n",
      "LinearSVC()\n",
      "accuracy\n",
      "0.8992084432717679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.90      0.98      0.94      1475\n",
      "      rumour       0.91      0.61      0.73       420\n",
      "\n",
      "    accuracy                           0.90      1895\n",
      "   macro avg       0.90      0.79      0.83      1895\n",
      "weighted avg       0.90      0.90      0.89      1895\n",
      "\n",
      "LogisticRegression()\n",
      "accuracy\n",
      "0.8316622691292876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.82      1.00      0.90      1475\n",
      "      rumour       0.96      0.25      0.40       420\n",
      "\n",
      "    accuracy                           0.83      1895\n",
      "   macro avg       0.89      0.62      0.65      1895\n",
      "weighted avg       0.85      0.83      0.79      1895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def do_multiple_10foldcrossvalidation(clfs,data,classifications):\n",
    "    for clf in clfs:\n",
    "        predictions = model_selection.cross_val_predict(clf, data,classifications, cv=10)\n",
    "        print (clf)\n",
    "        print (\"accuracy\")\n",
    "        print (accuracy_score(classifications,predictions))\n",
    "        print (classification_report(classifications,predictions))\n",
    "        \n",
    "do_multiple_10foldcrossvalidation(clfs,x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a6ca1",
   "metadata": {},
   "source": [
    "### Using td-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "121c3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to write manually for better tokenize\n",
    "td = TfidfVectorizer(stop_words='english')\n",
    "x_train = td.fit_transform(train_merge_events)\n",
    "x_dev = td.transform(dev_merge_events)\n",
    "\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#vectorizer = CountVectorizer(stop_words='english')\n",
    "#x_train  = vectorizer.fit_transform(train_merge_events)\n",
    "#x_dev = vectorizer.transform(dev_merge_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "035dc8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With alpha = 0.001 the accuracy of Naive Bayes is 0.91456\n",
      "With alpha = 0.005 the accuracy of Naive Bayes is 0.91772\n",
      "With alpha = 0.01 the accuracy of Naive Bayes is 0.90981\n",
      "With alpha = 0.1 the accuracy of Naive Bayes is 0.91772\n",
      "With alpha = 0.3 the accuracy of Naive Bayes is 0.88608\n",
      "With alpha = 0.5 the accuracy of Naive Bayes is 0.85285\n",
      "With alpha = 1 the accuracy of Naive Bayes is 0.79905\n",
      "The best setting for Naive Bayes is alpha = 0.005 with accuracy = 0.91772\n"
     ]
    }
   ],
   "source": [
    "# k fold to find the optimize hyperparameter\n",
    "alphas = [0.001,0.005,0.01,0.1,0.3,0.5,1]\n",
    "max_nb = 0\n",
    "for alpha in alphas:\n",
    "    nb = MultinomialNB(alpha=alpha)\n",
    "    nb_predict = nb.fit(x_train, y_train).predict(x_dev)    \n",
    "    nb_accuracy = accuracy_score(y_dev,nb_predict)\n",
    "    print('With alpha = {alpha} the accuracy of Naive Bayes is {acc:.5f}'.format(alpha=alpha, acc = nb_accuracy))\n",
    "    if nb_accuracy > max_nb:\n",
    "        max_nb = nb_accuracy\n",
    "        max_alpha = alpha\n",
    "print(\"The best setting for Naive Bayes is alpha = {alpha} with accuracy = {acc:.5f}\".format(alpha=max_alpha,acc=max_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1762c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
