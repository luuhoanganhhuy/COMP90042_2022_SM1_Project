{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a35d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f974c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_file = open('project-data/train.label.txt', 'r')\n",
    "train_labels = train_label_file.readlines()\n",
    "train_labels = [label.strip('\\n') for label in train_labels]\n",
    "    \n",
    "dev_label_file = open('project-data/dev.label.txt', 'r')\n",
    "dev_labels = dev_label_file.readlines()\n",
    "dev_labels = [label.strip('\\n') for label in dev_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce426aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open train text file\n",
    "f = open(f'./tweet_text.pckl','rb')\n",
    "train_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "# open dev text file\n",
    "f = open(f'./dev_tweet_text.pckl','rb')\n",
    "dev_data = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f8d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text) #remove @mention\n",
    "    text = re.sub(r'#','',text) # remove the hashtag symbol\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '',text) #remove hyperlink\n",
    "    text = re.sub(r'\\n','',text) # remove \\n \n",
    "    text = re.sub(r'\\r','',text) # remove \\r\n",
    "    text = re.sub(r'\\\\W+', ' ', text) #remove special characters\\n\",\n",
    "    return text\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    for j in range(len(train_data[i])):\n",
    "        train_data[i][j] = clean_text(train_data[i][j]).lower()\n",
    "        \n",
    "for i in range(len(dev_data)):\n",
    "    for j in range(len(dev_data[i])):\n",
    "        dev_data[i][j] = clean_text(dev_data[i][j]).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e188276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge source tweeet and reply tweet together for train data\n",
    "train_merge_events=[]\n",
    "for event in train_data:\n",
    "    merge = ''\n",
    "    for tweet in event:\n",
    "        merge = merge + tweet\n",
    "    train_merge_events.append(merge)\n",
    "    \n",
    "    \n",
    "# merge source tweeet and reply tweet together for dev data\n",
    "dev_merge_events=[]\n",
    "for event in dev_data:\n",
    "    merge = ''\n",
    "    for tweet in event:\n",
    "        merge = merge + tweet\n",
    "    dev_merge_events.append(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5. can regularly rinsing your nose with saline help prevent infection with the new coronavirus? 4. can eating garlic help prevent infection with the new coronavirus? covid19malaysia 6. do vaccines against pneumonia protect you against the new coronavirus? 7. can spraying alcohol or chlorine all over your body kill the new coronavirus? chamber 8. how effective are thermal scanners in detecting people infected with the new coronavirus? 9. can an ultraviolet disinfection lamp kill the new coronavirus? 10. are hand dryers effective in killing the new coronavirus? 11. the new coronavirus cannot be transmitted through mosquito bites. 12. taking a hot bath does not prevent the new coronavirus disease 13. cold weather and snow cannot kill the new coronavirus. 14. covid-19 virus can be transmitted in areas with hot and humid climates 15. drinking alcohol does not protect you against covid-19 and can be dangerous 16. being able to hold your breath for 10 seconds or more without coughing or feeling discomfort does not mean you are free from the coronavirus disease (covid-19) or any other lung disease. 17. you can recover from the coronavirus disease (covid-19). catching the new coronavirus does not mean you will have it for life. 18. exposing yourself to the sun or to temperatures higher than 25c degrees does not prevent the coronavirus disease (covid-19) 19. 5g mobile networks do not spread covid-19 '"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge_events[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5. can regularly rinsing your nose with saline...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>french police chief killed himself after charl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>coronavirus disease (covid-19) advice for the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ottawa police confirm that there were multiple...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>if the primary focus of a government isn't to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1890</th>\n",
       "      <td>desperate ted cruz claims planned parenthood s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>\"thoughts and prayers are not enough.\" pres. o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>police have surrounded this building where the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>joseph smith, who translated it by the gift...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>i can help! üë©‚Äçüè´9am: socialism - what is it an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1807 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     5. can regularly rinsing your nose with saline...      0\n",
       "1     french police chief killed himself after charl...      1\n",
       "2     coronavirus disease (covid-19) advice for the ...      0\n",
       "3     ottawa police confirm that there were multiple...      0\n",
       "4     if the primary focus of a government isn't to ...      0\n",
       "...                                                 ...    ...\n",
       "1890  desperate ted cruz claims planned parenthood s...      1\n",
       "1891  \"thoughts and prayers are not enough.\" pres. o...      1\n",
       "1892  police have surrounded this building where the...      0\n",
       "1893     joseph smith, who translated it by the gift...      0\n",
       "1894   i can help! üë©‚Äçüè´9am: socialism - what is it an...      0\n",
       "\n",
       "[1807 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame({'text':train_merge_events, 'label':train_labels})\n",
    "train_df['label'] = LabelEncoder().fit_transform(train_df['label'])\n",
    "nan_value = float(\"NaN\")\n",
    "train_df.replace(\"\", nan_value, inplace=True)\n",
    "train_df.dropna(axis=0 ,inplace=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid-19 fact:are hand dryers effective in kil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when can we expect the result of my husband's...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how does covid-19 spread? people can catch cov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>every news outlet using headlines like,\"are an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>researcher  on his encounter with a goliath bi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>or cure for covid-19. however, there are sever...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>after speculation that he‚Äôs been arrested, ban...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>*your questions answered*‚ùì*reply with the numb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>‚ñ∫anonymous operation kkk ‚ñ∫ku klux klan, we nev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>exposing yourself to the sun or to temperature...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    covid-19 fact:are hand dryers effective in kil...      0\n",
       "1     when can we expect the result of my husband's...      0\n",
       "2    how does covid-19 spread? people can catch cov...      0\n",
       "3    every news outlet using headlines like,\"are an...      0\n",
       "4    researcher  on his encounter with a goliath bi...      0\n",
       "..                                                 ...    ...\n",
       "627  or cure for covid-19. however, there are sever...      0\n",
       "628  after speculation that he‚Äôs been arrested, ban...      1\n",
       "629  *your questions answered*‚ùì*reply with the numb...      0\n",
       "630  ‚ñ∫anonymous operation kkk ‚ñ∫ku klux klan, we nev...      1\n",
       "631  exposing yourself to the sun or to temperature...      0\n",
       "\n",
       "[595 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df = pd.DataFrame({'text':dev_merge_events, 'label':dev_labels})\n",
    "dev_df['label'] = LabelEncoder().fit_transform(dev_df['label'])\n",
    "nan_value = float(\"NaN\")\n",
    "dev_df.replace(\"\", nan_value, inplace=True)\n",
    "dev_df.dropna(axis=0 ,inplace=True)\n",
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5. can regularly rinsing your nose with saline help prevent infection with the new coronavirus? 4. can eating garlic help prevent infection with the new coronavirus? covid19malaysia 6. do vaccines against pneumonia protect you against the new coronavirus? 7. can spraying alcohol or chlorine all over your body kill the new coronavirus? chamber 8. how effective are thermal scanners in detecting people infected with the new coronavirus? 9. can an ultraviolet disinfection lamp kill the new coronavirus? 10. are hand dryers effective in killing the new coronavirus? 11. the new coronavirus cannot be transmitted through mosquito bites. 12. taking a hot bath does not prevent the new coronavirus disease 13. cold weather and snow cannot kill the new coronavirus. 14. covid-19 virus can be transmitted in areas with hot and humid climates 15. drinking alcohol does not protect you against covid-19 and can be dangerous 16. being able to hold your breath for 10 seconds or more without coughing or feeling discomfort does not mean you are free from the coronavirus disease (covid-19) or any other lung disease. 17. you can recover from the coronavirus disease (covid-19). catching the new coronavirus does not mean you will have it for life. 18. exposing yourself to the sun or to temperatures higher than 25c degrees does not prevent the coronavirus disease (covid-19) 19. 5g mobile networks do not spread covid-19 '"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [1 if x== 'nonrumour' else 0 for x in train_labels]\n",
    "y_dev = [1 if x== 'nonrumour' else 0 for x in dev_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(train_df['text'].to_numpy())\n",
    "x_train = tokenizer.texts_to_sequences(train_df['text'].to_numpy())\n",
    "x_dev = tokenizer.texts_to_sequences(dev_df['text'].to_numpy())\n",
    "y_train = train_df['label'].to_numpy()\n",
    "y_dev = dev_df['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bow = tokenizer.texts_to_matrix(train_df['text'].to_numpy(), mode=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = x_train_bow.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26116"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_train = 0\n",
    "for each in x_train:\n",
    "    l = len(each)\n",
    "    if l > max_train:\n",
    "        max_train = l\n",
    "\n",
    "max_dev = 0\n",
    "for each in x_dev:\n",
    "    l = len(each)\n",
    "    if l > max_dev:\n",
    "        max_dev = l\n",
    "\n",
    "if max_train > max_dev:\n",
    "    maxlen = max_train\n",
    "else:\n",
    "    maxlen = max_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "xseq_train = pad_sequences(x_train, padding='post', maxlen=512)\n",
    "xseq_dev = pad_sequences(x_dev, padding='post', maxlen=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = x_train.shape[1]\n",
    "embedding_dim = 10\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 512, 10)           261160    \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 262,011\n",
      "Trainable params: 262,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential(name=\"lstm\")\n",
    "model3.add(layers.Embedding(input_dim=vocab_size, \n",
    "                           output_dim=embedding_dim, \n",
    "                           input_length=512))\n",
    "model3.add(LSTM(10))\n",
    "model3.add(layers.Dense(1, activation='sigmoid'))\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1807 samples, validate on 595 samples\n",
      "Epoch 1/20\n",
      "1807/1807 [==============================] - 29s 16ms/step - loss: 0.5728 - accuracy: 0.7532 - val_loss: 0.5386 - val_accuracy: 0.7697\n",
      "Epoch 2/20\n",
      "1807/1807 [==============================] - 27s 15ms/step - loss: 0.5327 - accuracy: 0.7726 - val_loss: 0.5370 - val_accuracy: 0.7697\n",
      "Epoch 3/20\n",
      "1807/1807 [==============================] - 28s 15ms/step - loss: 0.5201 - accuracy: 0.7864 - val_loss: 0.5382 - val_accuracy: 0.7714\n",
      "Epoch 4/20\n",
      "1807/1807 [==============================] - 28s 16ms/step - loss: 0.5141 - accuracy: 0.7969 - val_loss: 0.5246 - val_accuracy: 0.7815\n",
      "Epoch 5/20\n",
      "1807/1807 [==============================] - 29s 16ms/step - loss: 0.5097 - accuracy: 0.7991 - val_loss: 0.5237 - val_accuracy: 0.7815\n",
      "Epoch 6/20\n",
      "1807/1807 [==============================] - 29s 16ms/step - loss: 0.5070 - accuracy: 0.7997 - val_loss: 0.5227 - val_accuracy: 0.7815\n",
      "Epoch 7/20\n",
      "1807/1807 [==============================] - 30s 17ms/step - loss: 0.5049 - accuracy: 0.7997 - val_loss: 0.5227 - val_accuracy: 0.7832\n",
      "Epoch 8/20\n",
      "1807/1807 [==============================] - 27s 15ms/step - loss: 0.5464 - accuracy: 0.7322 - val_loss: 0.6172 - val_accuracy: 0.5849\n",
      "Epoch 9/20\n",
      "1807/1807 [==============================] - 29s 16ms/step - loss: 0.5707 - accuracy: 0.5783 - val_loss: 0.5198 - val_accuracy: 0.6151\n",
      "Epoch 10/20\n",
      "1807/1807 [==============================] - 28s 16ms/step - loss: 0.5078 - accuracy: 0.7737 - val_loss: 0.4857 - val_accuracy: 0.7714\n",
      "Epoch 11/20\n",
      "1807/1807 [==============================] - 29s 16ms/step - loss: 0.4883 - accuracy: 0.7748 - val_loss: 0.4819 - val_accuracy: 0.7697\n",
      "Epoch 12/20\n",
      "1807/1807 [==============================] - 31s 17ms/step - loss: 0.4804 - accuracy: 0.7737 - val_loss: 0.4783 - val_accuracy: 0.7697\n",
      "Epoch 13/20\n",
      "1807/1807 [==============================] - 28s 15ms/step - loss: 0.4721 - accuracy: 0.7748 - val_loss: 0.4748 - val_accuracy: 0.7697\n",
      "Epoch 14/20\n",
      "1807/1807 [==============================] - 29s 16ms/step - loss: 0.4694 - accuracy: 0.7886 - val_loss: 0.4715 - val_accuracy: 0.7714\n",
      "Epoch 15/20\n",
      "1807/1807 [==============================] - 30s 17ms/step - loss: 0.4712 - accuracy: 0.7914 - val_loss: 0.4716 - val_accuracy: 0.7714\n",
      "Epoch 16/20\n",
      "1807/1807 [==============================] - 33s 18ms/step - loss: 0.4646 - accuracy: 0.7925 - val_loss: 0.4766 - val_accuracy: 0.7714\n",
      "Epoch 17/20\n",
      "1807/1807 [==============================] - 28s 16ms/step - loss: 0.4628 - accuracy: 0.7936 - val_loss: 0.4710 - val_accuracy: 0.7714\n",
      "Epoch 18/20\n",
      "1807/1807 [==============================] - 32s 18ms/step - loss: 0.4651 - accuracy: 0.7941 - val_loss: 0.4713 - val_accuracy: 0.7714\n",
      "Epoch 19/20\n",
      "1807/1807 [==============================] - 33s 19ms/step - loss: 0.4603 - accuracy: 0.7947 - val_loss: 0.4700 - val_accuracy: 0.7714\n",
      "Epoch 20/20\n",
      "1807/1807 [==============================] - 31s 17ms/step - loss: 0.4586 - accuracy: 0.7952 - val_loss: 0.4700 - val_accuracy: 0.7731\n",
      "Testing Accuracy:  0.7731\n"
     ]
    }
   ],
   "source": [
    "model3.fit(xseq_train, y_train, epochs=20, verbose=True, validation_data=(xseq_dev, y_dev), batch_size=10)\n",
    "\n",
    "loss, accuracy = model3.evaluate(xseq_dev, y_dev, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract embedding to see the similiarity between tweets???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f'./test_tweet_text.pckl','rb')\n",
    "test_data = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_data)):\n",
    "    for j in range(len(test_data[i])):\n",
    "        test_data[i][j] = clean_text(test_data[i][j]).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge_events=[]\n",
    "for event in test_data:\n",
    "    merge = ''\n",
    "    for tweet in event:\n",
    "        merge = merge + tweet\n",
    "    test_merge_events.append(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame({'text':test_merge_events})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_value = float(\"NaN\")\n",
    "\n",
    "test_df.replace(\"\", nan_value, inplace=True)\n",
    "\n",
    "test_df.dropna(axis=0 ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how does covid-19 spread?   thanks, wcco! you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_warrior i hate to keep saying it, but capital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>q. how are covid-19 and influenza viruses diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>una de les q&amp;amp;a on coronaviruses de la p√†gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@_truthpolitics we should absolutely blame the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>ex-marlboro man dies from smoking-related dise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>holy shit. doritos flavored mountain dew.all i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>banksy account joins cartoonists support for c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>_europe    q: how are the members of an int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>can covid-19 be caught from a person who has n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text\n",
       "0    how does covid-19 spread?   thanks, wcco! you ...\n",
       "1    _warrior i hate to keep saying it, but capital...\n",
       "2    q. how are covid-19 and influenza viruses diff...\n",
       "3    una de les q&amp;a on coronaviruses de la p√†gi...\n",
       "4    @_truthpolitics we should absolutely blame the...\n",
       "..                                                 ...\n",
       "553  ex-marlboro man dies from smoking-related dise...\n",
       "554  holy shit. doritos flavored mountain dew.all i...\n",
       "555  banksy account joins cartoonists support for c...\n",
       "556     _europe    q: how are the members of an int...\n",
       "557  can covid-19 be caught from a person who has n...\n",
       "\n",
       "[558 rows x 1 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.47003184426732425, 0.7731092572212219]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(xseq_dev, y_dev, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tokenizer.texts_to_sequences(test_df['text'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "xseq_test = pad_sequences(x_test, padding='post', maxlen=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model3.predict(xseq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict= prediction.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Id\": range(len(predict)),\"Predicted\": predict}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('lstm_predict.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ecc0b61db9e9093a96f44aca5c878becc762e487425b78cb8ac250d1027f538"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
