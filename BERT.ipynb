{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9a35d77f",
      "metadata": {
        "id": "9a35d77f"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "import configparser\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import nltk\n",
        "import string\n",
        "import collections\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction import DictVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "27f974c5",
      "metadata": {
        "id": "27f974c5"
      },
      "outputs": [],
      "source": [
        "# read data \n",
        "train_data_file = open('train.data.txt', 'r')\n",
        "train_lines = train_data_file.readlines()\n",
        "train_events =[]\n",
        "# Strips the newline character\n",
        "for line in train_lines:\n",
        "    train_events.append(list(map(int,line.strip('\\n').split(','))))\n",
        "    \n",
        "train_label_file = open('train.label.txt', 'r') \n",
        "train_labels = train_label_file.readlines()\n",
        "train_labels = [label.strip('\\n') for label in train_labels]\n",
        "\n",
        "\n",
        "dev_data_file = open('dev.data.txt', 'r')\n",
        "dev_lines = dev_data_file.readlines()\n",
        "dev_events =[]\n",
        "# Strips the newline character\n",
        "for line in dev_lines:\n",
        "    dev_events.append(list(map(int,line.strip('\\n').split(','))))\n",
        "    \n",
        "dev_label_file = open('dev.label.txt', 'r')\n",
        "dev_labels = dev_label_file.readlines()\n",
        "dev_labels = [label.strip('\\n') for label in dev_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e4e3125",
      "metadata": {
        "id": "3e4e3125"
      },
      "outputs": [],
      "source": [
        "# config to access tweeter API\n",
        "config = configparser.ConfigParser()\n",
        "config.read('config.ini')\n",
        "\n",
        "consumer_key = config['twitter']['consumer_key']\n",
        "consumer_secret = config['twitter']['consumer_secret']\n",
        "\n",
        "access_token = config['twitter']['access_token']\n",
        "access_token_secret = config['twitter']['access_token_secret']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50ac927c",
      "metadata": {
        "id": "50ac927c"
      },
      "outputs": [],
      "source": [
        "# authentication\n",
        "client = tweepy.Client(consumer_key=consumer_key, consumer_secret=consumer_secret,\n",
        "                                   access_token=access_token, access_token_secret=access_token_secret,wait_on_rate_limit=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdd867de",
      "metadata": {
        "id": "fdd867de"
      },
      "outputs": [],
      "source": [
        "# get_tweets only return 100 results, handle the case when there is more than 100\n",
        "def lookup_tweets(tweet_IDs, client):\n",
        "    full_tweets = []\n",
        "    tweet_count = len(tweet_IDs)\n",
        "    for i in range(int((tweet_count / 100) + 1)):\n",
        "        # Catch the last group if it is less than 100 tweets\n",
        "        end_loc = min((i + 1) * 100, tweet_count)\n",
        "        if tweet_IDs[i * 100:end_loc]:\n",
        "            tweets = client.get_tweets(tweet_IDs[i * 100:end_loc],user_auth=True).data\n",
        "            if tweets:\n",
        "                full_tweets.extend(tweets)\n",
        "    return full_tweets\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc875eec",
      "metadata": {
        "id": "bc875eec",
        "outputId": "a436dcc4-57d9-40df-ef2a-4801cfe9d2d7"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17744/1230150304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_events_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mevent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_events\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlookup_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtrain_event_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_events_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_event_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17744/631739775.py\u001b[0m in \u001b[0;36mlookup_tweets\u001b[1;34m(tweet_IDs, client)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mend_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtweet_IDs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_loc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_IDs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_loc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser_auth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mfull_tweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\tweepy\\client.py\u001b[0m in \u001b[0;36mget_tweets\u001b[1;34m(self, ids, user_auth, **params)\u001b[0m\n\u001b[0;32m   1701\u001b[0m                 \u001b[1;34m\"ids\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"expansions\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"media.fields\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"place.fields\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1702\u001b[0m                 \u001b[1;34m\"poll.fields\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tweet.fields\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"user.fields\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1703\u001b[1;33m             ), data_type=Tweet, user_auth=user_auth\n\u001b[0m\u001b[0;32m   1704\u001b[0m         )\n\u001b[0;32m   1705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\tweepy\\client.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         response = self.request(method, route, params=request_params,\n\u001b[1;32m--> 127\u001b[1;33m                                 json=json, user_auth=user_auth)\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_type\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\tweepy\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[0;32m     83\u001b[0m         with self.session.request(\n\u001b[0;32m     84\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mroute\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m             \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         ) as response:\n\u001b[0;32m     87\u001b[0m             log.debug(\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    527\u001b[0m         }\n\u001b[0;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    451\u001b[0m                 )\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m                 \u001b[0mchunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m             )\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\urllib3\\packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    438\u001b[0m                 \u001b[1;31m# Python 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                     \u001b[0mhttplib_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                     \u001b[1;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\http\\client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1371\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1373\u001b[1;33m                 \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1374\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\http\\client.py\u001b[0m in \u001b[0;36mbegin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m         \u001b[1;31m# read until we get a non-100 response\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"iso-8859-1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"status line\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1069\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1071\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1072\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1073\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mD:\\Anaconda\\envs\\CV\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m    927\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 929\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    930\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# get the text of all events\n",
        "train_events_text=[]\n",
        "for event in train_events:\n",
        "    results = lookup_tweets(event, client)\n",
        "    train_event_text=[tweet.text for tweet in results]\n",
        "    train_events_text.append(train_event_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ab73d8d",
      "metadata": {
        "id": "9ab73d8d"
      },
      "outputs": [],
      "source": [
        "# save data to pickle file\n",
        "f = open(f'./tweet_text.pckl','wb')\n",
        "pickle.dump(train_events_text,f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a9523f4",
      "metadata": {
        "id": "6a9523f4"
      },
      "outputs": [],
      "source": [
        "# get the text of all events\n",
        "dev_events_text=[]\n",
        "for event in dev_events:\n",
        "    results = lookup_tweets(event, client)\n",
        "    dev_event_text=[tweet.text for tweet in results]\n",
        "    dev_events_text.append(dev_event_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "140e26d0",
      "metadata": {
        "id": "140e26d0"
      },
      "outputs": [],
      "source": [
        "# save data to pickle file\n",
        "f = open(f'./dev_tweet_text.pckl','wb')\n",
        "pickle.dump(dev_events_text,f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce426aaf",
      "metadata": {
        "id": "ce426aaf"
      },
      "outputs": [],
      "source": [
        "# open train text file\n",
        "f = open(f'/tweet_text.pckl','rb')\n",
        "train_data = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "\n",
        "# open dev text file\n",
        "f = open(f'/dev_tweet_text.pckl','rb')\n",
        "dev_data = pickle.load(f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45f8d602",
      "metadata": {
        "id": "45f8d602"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = re.sub(r'@[A-Za-z0-9]+','',text) #remove @mention\n",
        "    text = re.sub(r'#','',text) # remove the hashtag symbol\n",
        "    text = re.sub(r'https?:\\/\\/\\S+', '',text) #remove hyperlink\n",
        "    text = re.sub(r'\\n','',text) # remove \\n \n",
        "    text = re.sub(r'\\r','',text) # remove \\r\n",
        "    text = re.sub(r'[0-9]+','',text) #remove all the number\n",
        "    return text\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "    for j in range(len(train_data[i])):\n",
        "        train_data[i][j] = clean_text(train_data[i][j])\n",
        "        \n",
        "for i in range(len(dev_data)):\n",
        "    for j in range(len(dev_data[i])):\n",
        "        dev_data[i][j] = clean_text(dev_data[i][j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IcTJP1AN1W8N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcTJP1AN1W8N",
        "outputId": "15cfefea-8907-4d2f-aa75-e6659ca11de3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['. Can regularly rinsing your nose with saline help prevent infection with the new coronavirus? ',\n",
              " '. Can eating garlic help prevent infection with the new coronavirus? COVIDMalaysia ',\n",
              " '. Do vaccines against pneumonia protect you against the new coronavirus? ',\n",
              " '. Can spraying alcohol or chlorine all over your body kill the new coronavirus? Chamber ',\n",
              " '. How effective are thermal scanners in detecting people infected with the new coronavirus? ',\n",
              " '. Can an ultraviolet disinfection lamp kill the new coronavirus? ',\n",
              " '. Are hand dryers effective in killing the new coronavirus? ',\n",
              " '. The new coronavirus CANNOT be transmitted through mosquito bites. ',\n",
              " '. Taking a hot bath does not prevent the new coronavirus disease ',\n",
              " '. Cold weather and snow CANNOT kill the new coronavirus. ',\n",
              " '. COVID- virus can be transmitted in areas with hot and humid climates ',\n",
              " '. Drinking alcohol does not protect you against COVID- and can be dangerous ',\n",
              " '. Being able to hold your breath for  seconds or more without coughing or feeling discomfort DOES NOT mean you are free from the coronavirus disease (COVID-) or any other lung disease. ',\n",
              " '. You can recover from the coronavirus disease (COVID-). Catching the new coronavirus DOES NOT mean you will have it for life. ',\n",
              " '. Exposing yourself to the sun or to temperatures higher than C degrees DOES NOT prevent the coronavirus disease (COVID-) ',\n",
              " '. G mobile networks DO NOT spread COVID- ']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd6f359c",
      "metadata": {
        "id": "dd6f359c"
      },
      "outputs": [],
      "source": [
        "# merge source tweeet and reply tweet together for train data\n",
        "train_merge_events=[]\n",
        "for event in train_data:\n",
        "    merge = ''\n",
        "    for tweet in event:\n",
        "        merge = merge + tweet\n",
        "    train_merge_events.append(merge)\n",
        "    \n",
        "    \n",
        "# merge source tweeet and reply tweet together for dev data\n",
        "dev_merge_events=[]\n",
        "for event in dev_data:\n",
        "    merge = ''\n",
        "    for tweet in event:\n",
        "        merge = merge + tweet\n",
        "    dev_merge_events.append(merge)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef4b3707",
      "metadata": {
        "id": "ef4b3707"
      },
      "outputs": [],
      "source": [
        "def tokenize_tweet(tweet):\n",
        "    \"\"\"Get all of the tokens in a set of tweets\"\"\"\n",
        "    twt = nltk.tokenize.TweetTokenizer()\n",
        "    # combine stop words and punctuation\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    stop = stopwords + list(string.punctuation)\n",
        "    # filter out stop words and punctuation and send to lower case\n",
        "    tokens = [token.lower() for token in twt.tokenize(tweet)\n",
        "              if token.lower() not in stop]\n",
        "    tokens = [word for word in tokens if re.search('[a-zA-Z]',word) is not None] # filter out word not contain alphabet\n",
        "    return(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af32163e",
      "metadata": {
        "id": "af32163e"
      },
      "outputs": [],
      "source": [
        "def tokenize_tweetv2(tweet):\n",
        "    \"\"\"Get all of the tokens in a set of tweets\"\"\"\n",
        "    twt = nltk.tokenize.TweetTokenizer()\n",
        "    # combine stop words and punctuation\n",
        "    stopwords = nltk.corpus.stopwords.words('english')\n",
        "    stop = stopwords + list(string.punctuation)\n",
        "    # create the stemmer\n",
        "    stemmer = nltk.stem.porter.PorterStemmer()\n",
        "    # filter out stop words and punctuation and send to lower case\n",
        "    tokens = [ stemmer.stem(token) for token in twt.tokenize(tweet)\n",
        "              if token.lower() not in stop]\n",
        "    return(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48e9d6b0",
      "metadata": {
        "id": "48e9d6b0"
      },
      "source": [
        "### Normal bag of word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeb6e777",
      "metadata": {
        "id": "eeb6e777"
      },
      "outputs": [],
      "source": [
        "# Create bag of word \n",
        "def bow(data,labels):\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in range(len(data)):\n",
        "        tokens = tokenize_tweet(data[i])\n",
        "        \n",
        "        vocab = collections.defaultdict(int)\n",
        "        for word in tokens:\n",
        "            vocab[word] += 1 \n",
        "        x.append(vocab)\n",
        "        y.append(labels[i])\n",
        "    return x,y\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d5f2cb5",
      "metadata": {
        "id": "1d5f2cb5"
      },
      "outputs": [],
      "source": [
        "x_train,y_train = bow(train_merge_events,train_labels)\n",
        "x_dev,y_dev = bow(dev_merge_events,dev_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6e0e163",
      "metadata": {
        "id": "b6e0e163"
      },
      "outputs": [],
      "source": [
        "vectorizer = DictVectorizer()\n",
        "x_train = vectorizer.fit_transform(x_train)\n",
        "x_dev = vectorizer.transform(x_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f1d51de",
      "metadata": {
        "id": "1f1d51de",
        "outputId": "ef223b8d-daaf-4b80-92f5-04f3497910ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With alpha = 0.001 the accuracy of Naive Bayes is 0.90032\n",
            "With alpha = 0.005 the accuracy of Naive Bayes is 0.89715\n",
            "With alpha = 0.01 the accuracy of Naive Bayes is 0.88924\n",
            "With alpha = 0.1 the accuracy of Naive Bayes is 0.88608\n",
            "With alpha = 0.3 the accuracy of Naive Bayes is 0.87816\n",
            "With alpha = 0.5 the accuracy of Naive Bayes is 0.88133\n",
            "With alpha = 1 the accuracy of Naive Bayes is 0.88608\n",
            "The best setting for Naive Bayes is alpha = 0.001 with accuracy = 0.90032\n"
          ]
        }
      ],
      "source": [
        "# k fold to find the optimize hyperparameter\n",
        "alphas = [0.001,0.005,0.01,0.1,0.3,0.5,1]\n",
        "max_nb = 0\n",
        "for alpha in alphas:\n",
        "    nb = MultinomialNB(alpha=alpha)\n",
        "    nb_predict = nb.fit(x_train, y_train).predict(x_dev)    \n",
        "    nb_accuracy = accuracy_score(y_dev,nb_predict)\n",
        "    print('With alpha = {alpha} the accuracy of Naive Bayes is {acc:.5f}'.format(alpha=alpha, acc = nb_accuracy))\n",
        "    if nb_accuracy > max_nb:\n",
        "        max_nb = nb_accuracy\n",
        "        max_alpha = alpha\n",
        "print(\"The best setting for Naive Bayes is alpha = {alpha} with accuracy = {acc:.5f}\".format(alpha=max_alpha,acc=max_nb))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fb7355f",
      "metadata": {
        "id": "3fb7355f",
        "outputId": "383b2f11-fd96-420d-ee0e-d703ebbdb1cd",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using this solver  newton-cg\n",
            "With C = 100 and solver  = newton-cg the acciracy of Logistic Regression is 0.9113924050632911\n",
            "With C = 10 and solver  = newton-cg the acciracy of Logistic Regression is 0.9145569620253164\n",
            "With C = 1.0 and solver  = newton-cg the acciracy of Logistic Regression is 0.9129746835443038\n",
            "With C = 0.1 and solver  = newton-cg the acciracy of Logistic Regression is 0.8876582278481012\n",
            "With C = 0.01 and solver  = newton-cg the acciracy of Logistic Regression is 0.8433544303797469\n",
            "With C = 0.001 and solver  = newton-cg the acciracy of Logistic Regression is 0.7958860759493671\n",
            "Using this solver  lbfgs\n",
            "With C = 100 and solver  = lbfgs the acciracy of Logistic Regression is 0.9113924050632911\n",
            "With C = 10 and solver  = lbfgs the acciracy of Logistic Regression is 0.9145569620253164\n",
            "With C = 1.0 and solver  = lbfgs the acciracy of Logistic Regression is 0.9129746835443038\n",
            "With C = 0.1 and solver  = lbfgs the acciracy of Logistic Regression is 0.8876582278481012\n",
            "With C = 0.01 and solver  = lbfgs the acciracy of Logistic Regression is 0.8433544303797469\n",
            "With C = 0.001 and solver  = lbfgs the acciracy of Logistic Regression is 0.7958860759493671\n",
            "Using this solver  liblinear\n",
            "With C = 100 and solver  = liblinear the acciracy of Logistic Regression is 0.9113924050632911\n",
            "With C = 10 and solver  = liblinear the acciracy of Logistic Regression is 0.9129746835443038\n",
            "With C = 1.0 and solver  = liblinear the acciracy of Logistic Regression is 0.9129746835443038\n",
            "With C = 0.1 and solver  = liblinear the acciracy of Logistic Regression is 0.8987341772151899\n",
            "With C = 0.01 and solver  = liblinear the acciracy of Logistic Regression is 0.8544303797468354\n",
            "With C = 0.001 and solver  = liblinear the acciracy of Logistic Regression is 0.8306962025316456\n",
            "Using this solver  sag\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With C = 100 and solver  = sag the acciracy of Logistic Regression is 0.9272151898734177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With C = 10 and solver  = sag the acciracy of Logistic Regression is 0.9272151898734177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With C = 1.0 and solver  = sag the acciracy of Logistic Regression is 0.9272151898734177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With C = 0.1 and solver  = sag the acciracy of Logistic Regression is 0.9224683544303798\n",
            "With C = 0.01 and solver  = sag the acciracy of Logistic Regression is 0.9145569620253164\n",
            "With C = 0.001 and solver  = sag the acciracy of Logistic Regression is 0.8781645569620253\n",
            "Using this solver  saga\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With C = 100 and solver  = saga the acciracy of Logistic Regression is 0.9272151898734177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With C = 10 and solver  = saga the acciracy of Logistic Regression is 0.9272151898734177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With C = 1.0 and solver  = saga the acciracy of Logistic Regression is 0.9272151898734177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With C = 0.1 and solver  = saga the acciracy of Logistic Regression is 0.9240506329113924\n",
            "With C = 0.01 and solver  = saga the acciracy of Logistic Regression is 0.9145569620253164\n",
            "With C = 0.001 and solver  = saga the acciracy of Logistic Regression is 0.8718354430379747\n",
            "The best setting for Logistic Regression is c = 100 and solver = sag with accuracy = 0.92722\n"
          ]
        }
      ],
      "source": [
        "solvers = ['newton-cg', 'lbfgs', 'liblinear','sag','saga']\n",
        "c_values = [ 100,10,1.0, 0.1, 0.01,0.001]\n",
        "max_lr = 0\n",
        "for solver in solvers:\n",
        "    print('Using this solver ',solver )\n",
        "    for c_value in c_values:\n",
        "        lr = LogisticRegression(C=c_value, penalty='l2', solver=solver,max_iter=1000)\n",
        "        lr_predict = lr.fit(x_train, y_train).predict(x_dev)    \n",
        "        lr_accuracy = accuracy_score(y_dev,lr_predict)\n",
        "        print('With C = {c} and solver  = {sol} the acciracy of Logistic Regression is {acc}'.format(c=c_value,sol=solver,acc= lr_accuracy))\n",
        "        if lr_accuracy > max_lr:\n",
        "            max_lr = lr_accuracy\n",
        "            max_c_value = c_value\n",
        "            max_solver = solver\n",
        "print(\"The best setting for Logistic Regression is c = {c} and solver = {sol} with accuracy = {acc:.5f}\".format(c=max_c_value,sol=max_solver,acc=max_lr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2d4079c",
      "metadata": {
        "id": "e2d4079c"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clfs = [KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),\n",
        "        MultinomialNB(),LinearSVC(),LogisticRegression()]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e23fdf92",
      "metadata": {
        "id": "e23fdf92",
        "outputId": "0f83f201-3061-447a-c0ea-9964a9c68a5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier()\n",
            "accuracy\n",
            "0.7915567282321899\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   nonrumour       0.79      1.00      0.88      1475\n",
            "      rumour       0.86      0.07      0.13       420\n",
            "\n",
            "    accuracy                           0.79      1895\n",
            "   macro avg       0.82      0.53      0.51      1895\n",
            "weighted avg       0.81      0.79      0.72      1895\n",
            "\n",
            "DecisionTreeClassifier()\n",
            "accuracy\n",
            "0.833245382585752\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   nonrumour       0.88      0.91      0.89      1475\n",
            "      rumour       0.64      0.56      0.60       420\n",
            "\n",
            "    accuracy                           0.83      1895\n",
            "   macro avg       0.76      0.73      0.75      1895\n",
            "weighted avg       0.83      0.83      0.83      1895\n",
            "\n",
            "RandomForestClassifier()\n",
            "accuracy\n",
            "0.8401055408970977\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   nonrumour       0.83      0.99      0.91      1475\n",
            "      rumour       0.93      0.30      0.45       420\n",
            "\n",
            "    accuracy                           0.84      1895\n",
            "   macro avg       0.88      0.65      0.68      1895\n",
            "weighted avg       0.86      0.84      0.81      1895\n",
            "\n",
            "MultinomialNB()\n",
            "accuracy\n",
            "0.7968337730870713\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   nonrumour       0.79      1.00      0.88      1475\n",
            "      rumour       0.95      0.09      0.16       420\n",
            "\n",
            "    accuracy                           0.80      1895\n",
            "   macro avg       0.87      0.54      0.52      1895\n",
            "weighted avg       0.83      0.80      0.72      1895\n",
            "\n",
            "LinearSVC()\n",
            "accuracy\n",
            "0.8992084432717679\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   nonrumour       0.90      0.98      0.94      1475\n",
            "      rumour       0.91      0.61      0.73       420\n",
            "\n",
            "    accuracy                           0.90      1895\n",
            "   macro avg       0.90      0.79      0.83      1895\n",
            "weighted avg       0.90      0.90      0.89      1895\n",
            "\n",
            "LogisticRegression()\n",
            "accuracy\n",
            "0.8316622691292876\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   nonrumour       0.82      1.00      0.90      1475\n",
            "      rumour       0.96      0.25      0.40       420\n",
            "\n",
            "    accuracy                           0.83      1895\n",
            "   macro avg       0.89      0.62      0.65      1895\n",
            "weighted avg       0.85      0.83      0.79      1895\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def do_multiple_10foldcrossvalidation(clfs,data,classifications):\n",
        "    for clf in clfs:\n",
        "        predictions = model_selection.cross_val_predict(clf, data,classifications, cv=10)\n",
        "        print (clf)\n",
        "        print (\"accuracy\")\n",
        "        print (accuracy_score(classifications,predictions))\n",
        "        print (classification_report(classifications,predictions))\n",
        "        \n",
        "do_multiple_10foldcrossvalidation(clfs,x_train,y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc650265",
      "metadata": {
        "id": "fc650265"
      },
      "source": [
        "### Using td-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6370b51",
      "metadata": {
        "id": "e6370b51"
      },
      "outputs": [],
      "source": [
        "# need to write manually for better tokenize\n",
        "td = TfidfVectorizer(stop_words='english')\n",
        "x_train = td.fit_transform(train_merge_events)\n",
        "x_dev = td.transform(dev_merge_events)\n",
        "\n",
        "#from sklearn.feature_extraction.text import CountVectorizer\n",
        "#vectorizer = CountVectorizer(stop_words='english')\n",
        "#x_train  = vectorizer.fit_transform(train_merge_events)\n",
        "#x_dev = vectorizer.transform(dev_merge_events)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "649f92ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "649f92ac",
        "outputId": "30136108-362a-4df7-c680-055094949524"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With alpha = 0.001 the accuracy of Naive Bayes is 0.91139\n",
            "With alpha = 0.005 the accuracy of Naive Bayes is 0.91297\n",
            "With alpha = 0.01 the accuracy of Naive Bayes is 0.90190\n",
            "With alpha = 0.1 the accuracy of Naive Bayes is 0.92089\n",
            "With alpha = 0.3 the accuracy of Naive Bayes is 0.88449\n",
            "With alpha = 0.5 the accuracy of Naive Bayes is 0.85601\n",
            "With alpha = 1 the accuracy of Naive Bayes is 0.80380\n",
            "The best setting for Naive Bayes is alpha = 0.1 with accuracy = 0.92089\n"
          ]
        }
      ],
      "source": [
        "# k fold to find the optimize hyperparameter\n",
        "alphas = [0.001,0.005,0.01,0.1,0.3,0.5,1]\n",
        "max_nb = 0\n",
        "for alpha in alphas:\n",
        "    nb = MultinomialNB(alpha=alpha)\n",
        "    nb_predict = nb.fit(x_train, train_labels).predict(x_dev)    \n",
        "    nb_accuracy = accuracy_score(dev_labels,nb_predict)\n",
        "    print('With alpha = {alpha} the accuracy of Naive Bayes is {acc:.5f}'.format(alpha=alpha, acc = nb_accuracy))\n",
        "    if nb_accuracy > max_nb:\n",
        "        max_nb = nb_accuracy\n",
        "        max_alpha = alpha\n",
        "print(\"The best setting for Naive Bayes is alpha = {alpha} with accuracy = {acc:.5f}\".format(alpha=max_alpha,acc=max_nb))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "820b5163",
      "metadata": {
        "id": "820b5163"
      },
      "source": [
        "### BERT\n",
        "Google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9cfbac9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cfbac9a",
        "outputId": "4afbbb47-dd36-4374-9f72-89ef77b4ddbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 53.1 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 43.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 42.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e435b4",
      "metadata": {
        "id": "41e435b4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dhHyWQDopcj4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "ec3521cf1c7b41aa9c42820af4ad8926",
            "0244c1f8ec4645fbafbce77dd684d89b",
            "bc48924ec4104f66a144751c8003aaeb",
            "eb131f3657144859a1e133cd9a66fff4",
            "87647db4b1d84b3c9dfec54048b634c1",
            "32727a020e2344f09582dfb01de1fb33",
            "7e92557bb2c74aa9af6188aaaecd83d4",
            "e919135755224b04bff73b53b81924ac",
            "80b4fbdae58f424594e6cf49d44e6eff",
            "9003c0273d3741ae88105fbdb1ef95bb",
            "9f5fda32585f4d6fb22e3bb57fe37fa8",
            "28683dc4857e40a3a33fe9fb2759c83a",
            "a18eab15cda545a5a557783f711fbfac",
            "0fc17b14d7b24db19fd84480371897b6",
            "0415798ce1414f6d972f0c4179582205",
            "0bfb5f66fbd94825bf96e51e75cbccbb",
            "4b9eb589151147a1b067c5fb27ee321d",
            "dbdfdcf29d0f42d1a8af3263addb40c7",
            "1c6f938f48da4695bd99570d8445dd9f",
            "dd7e52691c234ecca06c84d31e294fc7",
            "da80f8a3f7654bfa9aa5fd6b0c434468",
            "52ee9d7cc4c346098881892885c495dd"
          ]
        },
        "id": "dhHyWQDopcj4",
        "outputId": "ba577689-0c39-440f-fbd4-f5546e5fc94e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec3521cf1c7b41aa9c42820af4ad8926"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28683dc4857e40a3a33fe9fb2759c83a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done loading BERT model.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "print(\"Done loading BERT model.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8k17okjUpskU",
      "metadata": {
        "id": "8k17okjUpskU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "a93e8318cb2348fe846faf5412b4dad1",
            "b7233cf44a8945cebc1da8d8472a39e2",
            "4d3832af09bd4fd7be328190b006bd9a",
            "398ef19d1d3243ac8c690bfc52c66a54",
            "dcc67c6518524315a88a1b0eca2ae6aa",
            "32afedcb27df4fbeac66c0449efab13c",
            "bb2fa77896674950a3f2d73839950431",
            "503e0ef47f364dc68bdc61b018f5b68a",
            "281d55cde4ab4a6eae7f424e5adcfe02",
            "ba02f2e1027d4b9ca8e30bc60e01fc8b",
            "7c7639eaa3c74d598f9f508abe00a560",
            "1fb58ddc57ef4239b2b97a7943481405",
            "f95a3d5ecf92416e8a056f909e16e4c6",
            "4fd5ad2d007641b085d5884239240216",
            "ea3c6aabd3554cb49b1d27ac7d371e79",
            "9fefbfe34acb4231a90d3207648cbbb8",
            "fbd41560d9c1499ab4738a16799663bb",
            "b0ae619a4b7c4675be35ccbd7cf2929f",
            "1ba8fa0477a54e0c9f35f0ae1da5b094",
            "b346e59b695c46969cbea32c632a7628",
            "a6ee4fdc36eb4a1bb591ad7c76f3e112",
            "508df162d60a4fde96a2c88aae8e7dcc"
          ]
        },
        "outputId": "9c92b5fb-1fd9-4110-c8d3-22104ebc7974"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a93e8318cb2348fe846faf5412b4dad1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fb58ddc57ef4239b2b97a7943481405"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "#load BERT's WordPiece tokenisation model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T4Nn_JEUsaOl",
      "metadata": {
        "id": "T4Nn_JEUsaOl"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.tokenize(event[0])\n",
        "# tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
        "tokens = ['[CLS]'] + tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P0Vh6rfctB6-",
      "metadata": {
        "id": "P0Vh6rfctB6-"
      },
      "outputs": [],
      "source": [
        "tokens=['CLS']\n",
        "for tweet in event:\n",
        "  t_tokens = tokenizer.tokenize(tweet)\n",
        "  tokens = tokens + t_tokens + ['[SEP]']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7ykNY4Po0bER",
      "metadata": {
        "id": "7ykNY4Po0bER"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "\n",
        "class SSTDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filename, maxlen):\n",
        "\n",
        "        #Store the contents of the file in a pandas dataframe\n",
        "        self.df = pd.read_csv(filename, delimiter = '\\t')\n",
        "\n",
        "        #Initialize the BERT tokenizer\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        #Selecting the sentence and label at the specified index in the data frame\n",
        "        sentence = self.df.loc[index, 'sentence']\n",
        "        label = self.df.loc[index, 'label']\n",
        "\n",
        "        #Preprocessing the text to be suitable for BERT\n",
        "        tokens = self.tokenizer.tokenize(sentence) #Tokenize the sentence\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]'] #Insering the CLS and SEP token in the beginning and end of the sentence\n",
        "        if len(tokens) < self.maxlen:\n",
        "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
        "\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
        "\n",
        "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "MRdMMxDW7U_i",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRdMMxDW7U_i",
        "outputId": "e12816b1-a5be-4e8e-c7e2-f9ec041b24b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done preprocessing training and development data.\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Creating instances of training and development set\n",
        "#maxlen sets the maximum length a sentence can have\n",
        "#any sentence longer than this length is truncated to the maxlen size\n",
        "train_set = SSTDataset(filename = 'train.tsv', maxlen = 512)\n",
        "dev_set = SSTDataset(filename = 'dev.tsv', maxlen = 512)\n",
        "\n",
        "#Creating intsances of training and development dataloaders\n",
        "train_loader = DataLoader(train_set,batch_size = 4, num_workers = 0)\n",
        "dev_loader = DataLoader(dev_set, batch_size = 4, num_workers = 0)\n",
        "\n",
        "print(\"Done preprocessing training and development data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "Cxrpv1qP8oKx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxrpv1qP8oKx",
        "outputId": "ce15016b-f38a-48a5-a312-1ba683c0a5d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7facb4867710>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "train_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "RSrj5mXU7yhz",
      "metadata": {
        "id": "RSrj5mXU7yhz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        #Instantiating BERT model object \n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        #Classification layer\n",
        "        #input dimension is 768 because [CLS] embedding has a dimension of 768\n",
        "        #output dimension is 1 because we're working with a binary classification problem\n",
        "        self.cls_layer = nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        '''\n",
        "        Inputs:\n",
        "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
        "        '''\n",
        "\n",
        "        #Feeding the input to BERT model to obtain contextualized representations\n",
        "        outputs = self.bert_layer(seq, attention_mask = attn_masks, return_dict=True)\n",
        "        cont_reps = outputs.last_hidden_state\n",
        "\n",
        "        #Obtaining the representation of [CLS] head (the first token)\n",
        "        cls_rep = cont_reps[:, 0]\n",
        "\n",
        "        #Feeding cls_rep to the classifier layer\n",
        "        logits = self.cls_layer(cls_rep)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "vZ76-l0A77Bo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ76-l0A77Bo",
        "outputId": "6974c98f-b90b-4916-9d44-c016f1c3debc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done creating the sentiment classifier.\n"
          ]
        }
      ],
      "source": [
        "gpu = 0 #gpu ID\n",
        "\n",
        "print(\"Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\")\n",
        "net = SentimentClassifier()\n",
        "net.cuda(gpu) #Enable gpu support for the model\n",
        "print(\"Done creating the sentiment classifier.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "qNNd83vr8LAL",
      "metadata": {
        "id": "qNNd83vr8LAL"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "opti = optim.Adam(net.parameters(), lr = 2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c8occKO88EcH",
      "metadata": {
        "id": "c8occKO88EcH"
      },
      "outputs": [],
      "source": [
        "def get_accuracy_from_logits(logits, labels):\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "    soft_probs = (probs > 0.5).long()\n",
        "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
        "    return acc\n",
        "\n",
        "def evaluate(net, criterion, dataloader, gpu):\n",
        "    net.eval()\n",
        "\n",
        "    mean_acc, mean_loss = 0, 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for seq, attn_masks, labels in dataloader:\n",
        "            seq, attn_masks, labels = seq.cuda(gpu), attn_masks.cuda(gpu), labels.cuda(gpu)\n",
        "            logits = net(seq, attn_masks)\n",
        "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
        "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
        "            count += 1\n",
        "\n",
        "    return mean_acc / count, mean_loss / count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "z2QV4Pxz8Jz7",
      "metadata": {
        "id": "z2QV4Pxz8Jz7"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def train(net, criterion, opti, train_loader, dev_loader, max_eps, gpu):\n",
        "\n",
        "    best_acc = 0\n",
        "    st = time.time()\n",
        "    for ep in range(max_eps):\n",
        "        \n",
        "        net.train()\n",
        "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "            #Clear gradients\n",
        "            opti.zero_grad()  \n",
        "            #Converting these to cuda tensors\n",
        "            seq, attn_masks, labels = seq.cuda(gpu), attn_masks.cuda(gpu), labels.cuda(gpu)\n",
        "\n",
        "            #Obtaining the logits from the model\n",
        "            logits = net(seq, attn_masks)\n",
        "\n",
        "            #Computing loss\n",
        "            loss = criterion(logits.squeeze(-1), labels.float())\n",
        "\n",
        "            #Backpropagating the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            #Optimization step\n",
        "            opti.step()\n",
        "              \n",
        "            if it % 100 == 0:\n",
        "                \n",
        "                acc = get_accuracy_from_logits(logits, labels)\n",
        "                print(\"Iteration {} of epoch {} complete. Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n",
        "                st = time.time()\n",
        "\n",
        "        \n",
        "        dev_acc, dev_loss = evaluate(net, criterion, dev_loader, gpu)\n",
        "        print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(ep, dev_acc, dev_loss))\n",
        "        if dev_acc > best_acc:\n",
        "            print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n",
        "            best_acc = dev_acc\n",
        "            torch.save(net.state_dict(), 'sstcls_{}.dat'.format(ep))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "OcEZotJw8Smo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcEZotJw8Smo",
        "outputId": "4a092519-5289-40b8-a63f-dc73812ca305"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0 of epoch 0 complete. Loss: 0.6499412059783936; Accuracy: 0.5; Time taken (s): 1.0964243412017822\n",
            "Iteration 100 of epoch 0 complete. Loss: 0.4843035936355591; Accuracy: 0.75; Time taken (s): 101.29129362106323\n",
            "Iteration 200 of epoch 0 complete. Loss: 0.1700078397989273; Accuracy: 1.0; Time taken (s): 101.6502194404602\n",
            "Iteration 300 of epoch 0 complete. Loss: 0.35970693826675415; Accuracy: 0.75; Time taken (s): 101.63419151306152\n",
            "Iteration 400 of epoch 0 complete. Loss: nan; Accuracy: 1.0; Time taken (s): 101.40207171440125\n",
            "Epoch 0 complete! Development Accuracy: 0.7684563994407654; Development Loss: nan\n",
            "Best development accuracy improved from 0 to 0.7684563994407654, saving model...\n"
          ]
        }
      ],
      "source": [
        "num_epoch = 1\n",
        "\n",
        "#fine-tune the model\n",
        "train(net, criterion, opti, train_loader, dev_loader, num_epoch, gpu)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filename, maxlen):\n",
        "\n",
        "        #Store the contents of the file in a pandas dataframe\n",
        "        self.df = pd.read_csv(filename, delimiter = '\\t')\n",
        "\n",
        "        #Initialize the BERT tokenizer\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        #Selecting the sentence and label at the specified index in the data frame\n",
        "        sentence = self.df.loc[index, 'sentence']\n",
        "\n",
        "        #Preprocessing the text to be suitable for BERT\n",
        "        tokens = self.tokenizer.tokenize(sentence) #Tokenize the sentence\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]'] #Insering the CLS and SEP token in the beginning and end of the sentence\n",
        "        if len(tokens) < self.maxlen:\n",
        "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
        "\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
        "\n",
        "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask"
      ],
      "metadata": {
        "id": "WavPjN3aBrgc"
      },
      "id": "WavPjN3aBrgc",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = TestDataset(filename = 'test.tsv', maxlen = 512)\n",
        "\n",
        "#Creating intsances of training and development dataloaders\n",
        "test_loader = DataLoader(test_set,batch_size = 1, num_workers = 0)"
      ],
      "metadata": {
        "id": "c24SOTcYEnVz"
      },
      "id": "c24SOTcYEnVz",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(net, test_loader):\n",
        "    # load weight\n",
        "    # net.load_state_dict(torch.load(weight_file))\n",
        "    \n",
        "    predictions = []\n",
        "    \n",
        "    # Predict process\n",
        "    with torch.no_grad():\n",
        "        for seq, attn_masks in test_loader:\n",
        "            seq, attn_masks = seq.cuda(gpu), attn_masks.cuda(gpu)\n",
        "            logits = net(seq, attn_masks)\n",
        "            probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "            soft_probs = (probs > 0.5).long()\n",
        "            predictions.append(soft_probs.cpu().numpy().squeeze())\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "i3oq_9ZcE6_p"
      },
      "id": "i3oq_9ZcE6_p",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weight_file = \"sstcls_0.dat\"\n",
        "prediction = predict(net, test_loader)"
      ],
      "metadata": {
        "id": "gTOFhGeeGGli"
      },
      "id": "gTOFhGeeGGli",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({\"Id\": range(len(prediction)),\"Predicted\": prediction}) \n",
        "df.to_csv('bert_test.csv',index=False)"
      ],
      "metadata": {
        "id": "rBKsPeMBG2mU"
      },
      "id": "rBKsPeMBG2mU",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "af50bd81",
      "metadata": {
        "id": "af50bd81"
      },
      "source": [
        "### LSTM\n",
        "model the source tweet and replies as a sequence of tweets using recurrent networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "004447d4",
      "metadata": {
        "id": "004447d4"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec3521cf1c7b41aa9c42820af4ad8926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0244c1f8ec4645fbafbce77dd684d89b",
              "IPY_MODEL_bc48924ec4104f66a144751c8003aaeb",
              "IPY_MODEL_eb131f3657144859a1e133cd9a66fff4"
            ],
            "layout": "IPY_MODEL_87647db4b1d84b3c9dfec54048b634c1"
          }
        },
        "0244c1f8ec4645fbafbce77dd684d89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32727a020e2344f09582dfb01de1fb33",
            "placeholder": "​",
            "style": "IPY_MODEL_7e92557bb2c74aa9af6188aaaecd83d4",
            "value": "Downloading: 100%"
          }
        },
        "bc48924ec4104f66a144751c8003aaeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e919135755224b04bff73b53b81924ac",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80b4fbdae58f424594e6cf49d44e6eff",
            "value": 570
          }
        },
        "eb131f3657144859a1e133cd9a66fff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9003c0273d3741ae88105fbdb1ef95bb",
            "placeholder": "​",
            "style": "IPY_MODEL_9f5fda32585f4d6fb22e3bb57fe37fa8",
            "value": " 570/570 [00:00&lt;00:00, 3.31kB/s]"
          }
        },
        "87647db4b1d84b3c9dfec54048b634c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32727a020e2344f09582dfb01de1fb33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e92557bb2c74aa9af6188aaaecd83d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e919135755224b04bff73b53b81924ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80b4fbdae58f424594e6cf49d44e6eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9003c0273d3741ae88105fbdb1ef95bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f5fda32585f4d6fb22e3bb57fe37fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28683dc4857e40a3a33fe9fb2759c83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a18eab15cda545a5a557783f711fbfac",
              "IPY_MODEL_0fc17b14d7b24db19fd84480371897b6",
              "IPY_MODEL_0415798ce1414f6d972f0c4179582205"
            ],
            "layout": "IPY_MODEL_0bfb5f66fbd94825bf96e51e75cbccbb"
          }
        },
        "a18eab15cda545a5a557783f711fbfac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b9eb589151147a1b067c5fb27ee321d",
            "placeholder": "​",
            "style": "IPY_MODEL_dbdfdcf29d0f42d1a8af3263addb40c7",
            "value": "Downloading: 100%"
          }
        },
        "0fc17b14d7b24db19fd84480371897b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c6f938f48da4695bd99570d8445dd9f",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd7e52691c234ecca06c84d31e294fc7",
            "value": 440473133
          }
        },
        "0415798ce1414f6d972f0c4179582205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da80f8a3f7654bfa9aa5fd6b0c434468",
            "placeholder": "​",
            "style": "IPY_MODEL_52ee9d7cc4c346098881892885c495dd",
            "value": " 420M/420M [00:13&lt;00:00, 36.3MB/s]"
          }
        },
        "0bfb5f66fbd94825bf96e51e75cbccbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b9eb589151147a1b067c5fb27ee321d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbdfdcf29d0f42d1a8af3263addb40c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c6f938f48da4695bd99570d8445dd9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd7e52691c234ecca06c84d31e294fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da80f8a3f7654bfa9aa5fd6b0c434468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52ee9d7cc4c346098881892885c495dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a93e8318cb2348fe846faf5412b4dad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b7233cf44a8945cebc1da8d8472a39e2",
              "IPY_MODEL_4d3832af09bd4fd7be328190b006bd9a",
              "IPY_MODEL_398ef19d1d3243ac8c690bfc52c66a54"
            ],
            "layout": "IPY_MODEL_dcc67c6518524315a88a1b0eca2ae6aa"
          }
        },
        "b7233cf44a8945cebc1da8d8472a39e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32afedcb27df4fbeac66c0449efab13c",
            "placeholder": "​",
            "style": "IPY_MODEL_bb2fa77896674950a3f2d73839950431",
            "value": "Downloading: 100%"
          }
        },
        "4d3832af09bd4fd7be328190b006bd9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_503e0ef47f364dc68bdc61b018f5b68a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_281d55cde4ab4a6eae7f424e5adcfe02",
            "value": 231508
          }
        },
        "398ef19d1d3243ac8c690bfc52c66a54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba02f2e1027d4b9ca8e30bc60e01fc8b",
            "placeholder": "​",
            "style": "IPY_MODEL_7c7639eaa3c74d598f9f508abe00a560",
            "value": " 226k/226k [00:00&lt;00:00, 974kB/s]"
          }
        },
        "dcc67c6518524315a88a1b0eca2ae6aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32afedcb27df4fbeac66c0449efab13c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb2fa77896674950a3f2d73839950431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "503e0ef47f364dc68bdc61b018f5b68a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "281d55cde4ab4a6eae7f424e5adcfe02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba02f2e1027d4b9ca8e30bc60e01fc8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c7639eaa3c74d598f9f508abe00a560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fb58ddc57ef4239b2b97a7943481405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f95a3d5ecf92416e8a056f909e16e4c6",
              "IPY_MODEL_4fd5ad2d007641b085d5884239240216",
              "IPY_MODEL_ea3c6aabd3554cb49b1d27ac7d371e79"
            ],
            "layout": "IPY_MODEL_9fefbfe34acb4231a90d3207648cbbb8"
          }
        },
        "f95a3d5ecf92416e8a056f909e16e4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbd41560d9c1499ab4738a16799663bb",
            "placeholder": "​",
            "style": "IPY_MODEL_b0ae619a4b7c4675be35ccbd7cf2929f",
            "value": "Downloading: 100%"
          }
        },
        "4fd5ad2d007641b085d5884239240216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ba8fa0477a54e0c9f35f0ae1da5b094",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b346e59b695c46969cbea32c632a7628",
            "value": 28
          }
        },
        "ea3c6aabd3554cb49b1d27ac7d371e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6ee4fdc36eb4a1bb591ad7c76f3e112",
            "placeholder": "​",
            "style": "IPY_MODEL_508df162d60a4fde96a2c88aae8e7dcc",
            "value": " 28.0/28.0 [00:00&lt;00:00, 773B/s]"
          }
        },
        "9fefbfe34acb4231a90d3207648cbbb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd41560d9c1499ab4738a16799663bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0ae619a4b7c4675be35ccbd7cf2929f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ba8fa0477a54e0c9f35f0ae1da5b094": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b346e59b695c46969cbea32c632a7628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6ee4fdc36eb4a1bb591ad7c76f3e112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "508df162d60a4fde96a2c88aae8e7dcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}