{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a35d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import configparser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27f974c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data \n",
    "train_data_file = open('project-data/train.data.txt', 'r')\n",
    "train_lines = train_data_file.readlines()\n",
    "train_events =[]\n",
    "# Strips the newline character\n",
    "for line in train_lines:\n",
    "    train_events.append(list(map(int,line.strip('\\n').split(','))))\n",
    "    \n",
    "train_label_file = open('project-data/train.label.txt', 'r')\n",
    "train_labels = train_label_file.readlines()\n",
    "train_labels = [label.strip('\\n') for label in train_labels]\n",
    "\n",
    "\n",
    "dev_data_file = open('project-data/dev.data.txt', 'r')\n",
    "dev_lines = dev_data_file.readlines()\n",
    "dev_events =[]\n",
    "# Strips the newline character\n",
    "for line in dev_lines:\n",
    "    dev_events.append(list(map(int,line.strip('\\n').split(','))))\n",
    "    \n",
    "dev_label_file = open('project-data/dev.label.txt', 'r')\n",
    "dev_labels = dev_label_file.readlines()\n",
    "dev_labels = [label.strip('\\n') for label in dev_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce426aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open train text file\n",
    "f = open(f'./tweet_text.pckl','rb')\n",
    "train_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "# open dev text file\n",
    "f = open(f'./dev_tweet_text.pckl','rb')\n",
    "dev_data = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f8d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text) #remove @mention\n",
    "    text = re.sub(r'#','',text) # remove the hashtag symbol\n",
    "    text = re.sub(r'https?:\\/\\/\\S+', '',text) #remove hyperlink\n",
    "    text = re.sub(r'\\n','',text) # remove \\n \n",
    "    return text\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    for j in range(len(train_data[i])):\n",
    "        train_data[i][j] = clean_text(train_data[i][j])\n",
    "        \n",
    "for i in range(len(dev_data)):\n",
    "    for j in range(len(dev_data[i])):\n",
    "        dev_data[i][j] = clean_text(dev_data[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e188276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge source tweeet and reply tweet together for train data\n",
    "train_merge_events=[]\n",
    "for event in train_data:\n",
    "    merge = ''\n",
    "    for tweet in event:\n",
    "        merge = merge + tweet\n",
    "    train_merge_events.append(merge)\n",
    "    \n",
    "    \n",
    "# merge source tweeet and reply tweet together for dev data\n",
    "dev_merge_events=[]\n",
    "for event in dev_data:\n",
    "    merge = ''\n",
    "    for tweet in event:\n",
    "        merge = merge + tweet\n",
    "    dev_merge_events.append(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86ecc06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweet(tweet):\n",
    "    \"\"\"Get all of the tokens in a set of tweets\"\"\"\n",
    "    twt = nltk.tokenize.TweetTokenizer()\n",
    "    # combine stop words and punctuation\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    stop = stopwords + list(string.punctuation)\n",
    "    # filter out stop words and punctuation and send to lower case\n",
    "    tokens = [token.lower() for token in twt.tokenize(tweet)\n",
    "              if token.lower() not in stop]\n",
    "    tokens = [word for word in tokens if re.search('[a-zA-Z]',word) is not None] # filter out word not contain alphabet\n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eedf7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_tweetv2(tweet):\n",
    "    \"\"\"Get all of the tokens in a set of tweets\"\"\"\n",
    "    twt = nltk.tokenize.TweetTokenizer()\n",
    "    # combine stop words and punctuation\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    stop = stopwords + list(string.punctuation)\n",
    "    # create the stemmer\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    # filter out stop words and punctuation and send to lower case\n",
    "    tokens = [ stemmer.stem(token) for token in twt.tokenize(tweet)\n",
    "              if token.lower() not in stop]\n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29a7d7",
   "metadata": {},
   "source": [
    "### Normal bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422ff238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of word \n",
    "def bow(data,labels):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(data)):\n",
    "        tokens = tokenize_tweet(data[i])\n",
    "        \n",
    "        vocab = collections.defaultdict(int)\n",
    "        for word in tokens:\n",
    "            vocab[word] += 1 \n",
    "        x.append(vocab)\n",
    "        y.append(labels[i])\n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68e7b60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = bow(train_merge_events,train_labels)\n",
    "x_dev,y_dev = bow(dev_merge_events,dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a1b9c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer()\n",
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_dev = vectorizer.transform(x_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e8eb610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With alpha = 0.001 the accuracy of Naive Bayes is 0.90032\n",
      "With alpha = 0.005 the accuracy of Naive Bayes is 0.89715\n",
      "With alpha = 0.01 the accuracy of Naive Bayes is 0.88924\n",
      "With alpha = 0.1 the accuracy of Naive Bayes is 0.88608\n",
      "With alpha = 0.3 the accuracy of Naive Bayes is 0.87816\n",
      "With alpha = 0.5 the accuracy of Naive Bayes is 0.88133\n",
      "With alpha = 1 the accuracy of Naive Bayes is 0.88608\n",
      "The best setting for Naive Bayes is alpha = 0.001 with accuracy = 0.90032\n"
     ]
    }
   ],
   "source": [
    "# k fold to find the optimize hyperparameter\n",
    "alphas = [0.001,0.005,0.01,0.1,0.3,0.5,1]\n",
    "max_nb = 0\n",
    "for alpha in alphas:\n",
    "    nb = MultinomialNB(alpha=alpha)\n",
    "    nb_predict = nb.fit(x_train, y_train).predict(x_dev)    \n",
    "    nb_accuracy = accuracy_score(y_dev,nb_predict)\n",
    "    print('With alpha = {alpha} the accuracy of Naive Bayes is {acc:.5f}'.format(alpha=alpha, acc = nb_accuracy))\n",
    "    if nb_accuracy > max_nb:\n",
    "        max_nb = nb_accuracy\n",
    "        max_alpha = alpha\n",
    "print(\"The best setting for Naive Bayes is alpha = {alpha} with accuracy = {acc:.5f}\".format(alpha=max_alpha,acc=max_nb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f27fe4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using this solver  newton-cg\n",
      "With C = 100 and solver  = newton-cg the acciracy of Logistic Regression is 0.9113924050632911\n",
      "With C = 10 and solver  = newton-cg the acciracy of Logistic Regression is 0.9145569620253164\n",
      "With C = 1.0 and solver  = newton-cg the acciracy of Logistic Regression is 0.9129746835443038\n",
      "With C = 0.1 and solver  = newton-cg the acciracy of Logistic Regression is 0.8876582278481012\n",
      "With C = 0.01 and solver  = newton-cg the acciracy of Logistic Regression is 0.8433544303797469\n",
      "With C = 0.001 and solver  = newton-cg the acciracy of Logistic Regression is 0.7958860759493671\n",
      "Using this solver  lbfgs\n",
      "With C = 100 and solver  = lbfgs the acciracy of Logistic Regression is 0.9113924050632911\n",
      "With C = 10 and solver  = lbfgs the acciracy of Logistic Regression is 0.9145569620253164\n",
      "With C = 1.0 and solver  = lbfgs the acciracy of Logistic Regression is 0.9129746835443038\n",
      "With C = 0.1 and solver  = lbfgs the acciracy of Logistic Regression is 0.8876582278481012\n",
      "With C = 0.01 and solver  = lbfgs the acciracy of Logistic Regression is 0.8433544303797469\n",
      "With C = 0.001 and solver  = lbfgs the acciracy of Logistic Regression is 0.7958860759493671\n",
      "Using this solver  liblinear\n",
      "With C = 100 and solver  = liblinear the acciracy of Logistic Regression is 0.9113924050632911\n",
      "With C = 10 and solver  = liblinear the acciracy of Logistic Regression is 0.9129746835443038\n",
      "With C = 1.0 and solver  = liblinear the acciracy of Logistic Regression is 0.9129746835443038\n",
      "With C = 0.1 and solver  = liblinear the acciracy of Logistic Regression is 0.8987341772151899\n",
      "With C = 0.01 and solver  = liblinear the acciracy of Logistic Regression is 0.8544303797468354\n",
      "With C = 0.001 and solver  = liblinear the acciracy of Logistic Regression is 0.8306962025316456\n",
      "Using this solver  sag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 100 and solver  = sag the acciracy of Logistic Regression is 0.9272151898734177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 10 and solver  = sag the acciracy of Logistic Regression is 0.9272151898734177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 1.0 and solver  = sag the acciracy of Logistic Regression is 0.9272151898734177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 0.1 and solver  = sag the acciracy of Logistic Regression is 0.9224683544303798\n",
      "With C = 0.01 and solver  = sag the acciracy of Logistic Regression is 0.9145569620253164\n",
      "With C = 0.001 and solver  = sag the acciracy of Logistic Regression is 0.8781645569620253\n",
      "Using this solver  saga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 100 and solver  = saga the acciracy of Logistic Regression is 0.9272151898734177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 10 and solver  = saga the acciracy of Logistic Regression is 0.9272151898734177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 1.0 and solver  = saga the acciracy of Logistic Regression is 0.9272151898734177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C = 0.1 and solver  = saga the acciracy of Logistic Regression is 0.9240506329113924\n",
      "With C = 0.01 and solver  = saga the acciracy of Logistic Regression is 0.9145569620253164\n",
      "With C = 0.001 and solver  = saga the acciracy of Logistic Regression is 0.8718354430379747\n",
      "The best setting for Logistic Regression is c = 100 and solver = sag with accuracy = 0.92722\n"
     ]
    }
   ],
   "source": [
    "solvers = ['newton-cg', 'lbfgs', 'liblinear','sag','saga']\n",
    "c_values = [ 100,10,1.0, 0.1, 0.01,0.001]\n",
    "max_lr = 0\n",
    "for solver in solvers:\n",
    "    print('Using this solver ',solver )\n",
    "    for c_value in c_values:\n",
    "        lr = LogisticRegression(C=c_value, penalty='l2', solver=solver,max_iter=1000)\n",
    "        lr_predict = lr.fit(x_train, y_train).predict(x_dev)    \n",
    "        lr_accuracy = accuracy_score(y_dev,lr_predict)\n",
    "        print('With C = {c} and solver  = {sol} the acciracy of Logistic Regression is {acc}'.format(c=c_value,sol=solver,acc= lr_accuracy))\n",
    "        if lr_accuracy > max_lr:\n",
    "            max_lr = lr_accuracy\n",
    "            max_c_value = c_value\n",
    "            max_solver = solver\n",
    "print(\"The best setting for Logistic Regression is c = {c} and solver = {sol} with accuracy = {acc:.5f}\".format(c=max_c_value,sol=max_solver,acc=max_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b53067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clfs = [KNeighborsClassifier(),DecisionTreeClassifier(),RandomForestClassifier(),\n",
    "        MultinomialNB(),LinearSVC(),LogisticRegression()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e45b38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "accuracy\n",
      "0.8158311345646438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.81      0.99      0.89      1475\n",
      "      rumour       0.84      0.21      0.34       420\n",
      "\n",
      "    accuracy                           0.82      1895\n",
      "   macro avg       0.83      0.60      0.61      1895\n",
      "weighted avg       0.82      0.82      0.77      1895\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "accuracy\n",
      "0.8321899736147758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.88      0.91      0.89      1475\n",
      "      rumour       0.64      0.56      0.60       420\n",
      "\n",
      "    accuracy                           0.83      1895\n",
      "   macro avg       0.76      0.73      0.75      1895\n",
      "weighted avg       0.83      0.83      0.83      1895\n",
      "\n",
      "RandomForestClassifier()\n",
      "accuracy\n",
      "0.8390501319261213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.84      0.98      0.90      1475\n",
      "      rumour       0.82      0.35      0.49       420\n",
      "\n",
      "    accuracy                           0.84      1895\n",
      "   macro avg       0.83      0.67      0.70      1895\n",
      "weighted avg       0.84      0.84      0.81      1895\n",
      "\n",
      "MultinomialNB()\n",
      "accuracy\n",
      "0.8633245382585752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.94      0.88      0.91      1475\n",
      "      rumour       0.66      0.81      0.72       420\n",
      "\n",
      "    accuracy                           0.86      1895\n",
      "   macro avg       0.80      0.84      0.82      1895\n",
      "weighted avg       0.88      0.86      0.87      1895\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "D:\\Anaconda\\envs\\CV\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC()\n",
      "accuracy\n",
      "0.8722955145118734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.90      0.93      0.92      1475\n",
      "      rumour       0.74      0.65      0.69       420\n",
      "\n",
      "    accuracy                           0.87      1895\n",
      "   macro avg       0.82      0.79      0.81      1895\n",
      "weighted avg       0.87      0.87      0.87      1895\n",
      "\n",
      "LogisticRegression()\n",
      "accuracy\n",
      "0.8949868073878628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.90      0.97      0.93      1475\n",
      "      rumour       0.86      0.63      0.73       420\n",
      "\n",
      "    accuracy                           0.89      1895\n",
      "   macro avg       0.88      0.80      0.83      1895\n",
      "weighted avg       0.89      0.89      0.89      1895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def do_multiple_10foldcrossvalidation(clfs,data,classifications):\n",
    "    for clf in clfs:\n",
    "        predictions = model_selection.cross_val_predict(clf, data,classifications, cv=10)\n",
    "        print (clf)\n",
    "        print (\"accuracy\")\n",
    "        print (accuracy_score(classifications,predictions))\n",
    "        print (classification_report(classifications,predictions))\n",
    "        \n",
    "do_multiple_10foldcrossvalidation(clfs,x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a6ca1",
   "metadata": {},
   "source": [
    "### Using td-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "121c3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to write manually for better tokenize\n",
    "td = TfidfVectorizer(stop_words='english')\n",
    "x_train = td.fit_transform(train_merge_events)\n",
    "x_dev = td.transform(dev_merge_events)\n",
    "\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#vectorizer = CountVectorizer(stop_words='english')\n",
    "#x_train  = vectorizer.fit_transform(train_merge_events)\n",
    "#x_dev = vectorizer.transform(dev_merge_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "035dc8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With alpha = 0.001 the accuracy of Naive Bayes is 0.91456\n",
      "With alpha = 0.005 the accuracy of Naive Bayes is 0.91772\n",
      "With alpha = 0.01 the accuracy of Naive Bayes is 0.90981\n",
      "With alpha = 0.1 the accuracy of Naive Bayes is 0.91772\n",
      "With alpha = 0.3 the accuracy of Naive Bayes is 0.88608\n",
      "With alpha = 0.5 the accuracy of Naive Bayes is 0.85285\n",
      "With alpha = 1 the accuracy of Naive Bayes is 0.79905\n",
      "The best setting for Naive Bayes is alpha = 0.005 with accuracy = 0.91772\n"
     ]
    }
   ],
   "source": [
    "# k fold to find the optimize hyperparameter\n",
    "alphas = [0.001,0.005,0.01,0.1,0.3,0.5,1]\n",
    "max_nb = 0\n",
    "for alpha in alphas:\n",
    "    nb = MultinomialNB(alpha=alpha)\n",
    "    nb_predict = nb.fit(x_train, y_train).predict(x_dev)    \n",
    "    nb_accuracy = accuracy_score(y_dev,nb_predict)\n",
    "    print('With alpha = {alpha} the accuracy of Naive Bayes is {acc:.5f}'.format(alpha=alpha, acc = nb_accuracy))\n",
    "    if nb_accuracy > max_nb:\n",
    "        max_nb = nb_accuracy\n",
    "        max_alpha = alpha\n",
    "print(\"The best setting for Naive Bayes is alpha = {alpha} with accuracy = {acc:.5f}\".format(alpha=max_alpha,acc=max_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b248c8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "accuracy\n",
      "0.7915567282321899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.79      1.00      0.88      1475\n",
      "      rumour       0.86      0.07      0.13       420\n",
      "\n",
      "    accuracy                           0.79      1895\n",
      "   macro avg       0.82      0.53      0.51      1895\n",
      "weighted avg       0.81      0.79      0.72      1895\n",
      "\n",
      "DecisionTreeClassifier()\n",
      "accuracy\n",
      "0.8316622691292876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.88      0.91      0.89      1475\n",
      "      rumour       0.63      0.57      0.60       420\n",
      "\n",
      "    accuracy                           0.83      1895\n",
      "   macro avg       0.76      0.74      0.75      1895\n",
      "weighted avg       0.83      0.83      0.83      1895\n",
      "\n",
      "RandomForestClassifier()\n",
      "accuracy\n",
      "0.8411609498680739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.84      0.99      0.91      1475\n",
      "      rumour       0.90      0.32      0.47       420\n",
      "\n",
      "    accuracy                           0.84      1895\n",
      "   macro avg       0.87      0.65      0.69      1895\n",
      "weighted avg       0.85      0.84      0.81      1895\n",
      "\n",
      "MultinomialNB()\n",
      "accuracy\n",
      "0.7968337730870713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.79      1.00      0.88      1475\n",
      "      rumour       0.95      0.09      0.16       420\n",
      "\n",
      "    accuracy                           0.80      1895\n",
      "   macro avg       0.87      0.54      0.52      1895\n",
      "weighted avg       0.83      0.80      0.72      1895\n",
      "\n",
      "LinearSVC()\n",
      "accuracy\n",
      "0.8992084432717679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.90      0.98      0.94      1475\n",
      "      rumour       0.91      0.61      0.73       420\n",
      "\n",
      "    accuracy                           0.90      1895\n",
      "   macro avg       0.90      0.79      0.83      1895\n",
      "weighted avg       0.90      0.90      0.89      1895\n",
      "\n",
      "LogisticRegression()\n",
      "accuracy\n",
      "0.8316622691292876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   nonrumour       0.82      1.00      0.90      1475\n",
      "      rumour       0.96      0.25      0.40       420\n",
      "\n",
      "    accuracy                           0.83      1895\n",
      "   macro avg       0.89      0.62      0.65      1895\n",
      "weighted avg       0.85      0.83      0.79      1895\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def do_multiple_10foldcrossvalidation(clfs,data,classifications):\n",
    "    for clf in clfs:\n",
    "        predictions = model_selection.cross_val_predict(clf, data,classifications, cv=10)\n",
    "        print (clf)\n",
    "        print (\"accuracy\")\n",
    "        print (accuracy_score(classifications,predictions))\n",
    "        print (classification_report(classifications,predictions))\n",
    "        \n",
    "do_multiple_10foldcrossvalidation(clfs,x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd279be4",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58c4ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data \n",
    "test_data_file = open('project-data/test.data.txt', 'r')\n",
    "test_lines = test_data_file.readlines()\n",
    "test_events =[]\n",
    "# Strips the newline character\n",
    "for line in test_lines:\n",
    "    test_events.append(list(map(int,line.strip('\\n').split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f0e0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=[]\n",
    "for event in test_events:\n",
    "    tweet_list=[]\n",
    "    for tweet in event: \n",
    "        f = open('project-data/tweet-objects/'+str(tweet)+'.json')\n",
    "        data = json.load(f)\n",
    "        tweet_list.append(data['text'])\n",
    "    test_data.append(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a20c3db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_data)):\n",
    "    for j in range(len(test_data[i])):\n",
    "        test_data[i][j] = clean_text(test_data[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3048c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merge_events=[]\n",
    "for event in test_data:\n",
    "    merge = ''\n",
    "    for tweet in event:\n",
    "        merge = merge + tweet\n",
    "    test_merge_events.append(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "99184b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "td = TfidfVectorizer(stop_words='english')\n",
    "x_train = td.fit_transform(train_merge_events)\n",
    "x_test = td.transform(test_merge_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3623d314",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB(alpha= 0.005)\n",
    "nb_predict = nb.fit(x_train, y_train).predict(x_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "670e3478",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=[]\n",
    "for result in nb_predict:\n",
    "    if result == \"nonrumour\":\n",
    "        predict.append(0)\n",
    "    else:\n",
    "        predict.append(1)\n",
    "df = pd.DataFrame({\"Id\": range(len(predict)),\"Predicted\": predict}) \n",
    "df.to_csv('nb_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a7294f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr_predict = lr.fit(x_train, y_train).predict(x_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c080a91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=[]\n",
    "for result in lr_predict:\n",
    "    if result == \"nonrumour\":\n",
    "        predict.append(0)\n",
    "    else:\n",
    "        predict.append(1)\n",
    "df = pd.DataFrame({\"Id\": range(len(predict)),\"Predicted\": predict}) \n",
    "df.to_csv('lr_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2333cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC = LinearSVC()\n",
    "SVC_predict = SVC.fit(x_train, y_train).predict(x_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6817f4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the highest score atm\n",
    "predict=[]\n",
    "for result in SVC_predict:\n",
    "    if result == \"nonrumour\":\n",
    "        predict.append(0)\n",
    "    else:\n",
    "        predict.append(1)\n",
    "df = pd.DataFrame({\"Id\": range(len(predict)),\"Predicted\": predict}) \n",
    "df.to_csv('svc_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa80d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
